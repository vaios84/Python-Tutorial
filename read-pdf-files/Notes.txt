Page 1
----------------------------------------------------------------------------------------------------<Knowledge-BasedSystems189(2020)105092
Contentslistsavailableat
ScienceDirect
Knowledge-BasedSystems
journalhomepage:
www.elsevier.com/locate/knosys
CNAVER:AContentandNetwork-basedAcademicVEnue
Recommendersystem
I
TribikramPradhan

,SukomalPal
DepartmentofComputerScienceandEngineering,IndianInstituteofTechnology(BHU),Varanasi,UttarPradesh,India
articleinfo
Articlehistory:
Received24April2019
Receivedinrevisedform1October2019
Accepted6October2019
Availableonline17October2019
Keywords:
Venuerecommendersystem
Socialnetworkanalysis
Meta-pathanalysis
Randomwalkwithrestart(RWR)
Graphclustering
Rank-basedfusion
abstract
Thephenomenonofrapidlydevelopingacademicvenuesposesasignificantchallengeforresearchers:
howtorecognizetheonesthatarenotonlyinaccordancewithonesscholarlyinterestsbutalso
ofhighsignificance?Often,evenahigh-qualitypaperisrejectedbecauseofamismatchbetweenthe
researchareaofthepaperandthescopeofthejournal.Recommendingappropriatescholarlyvenuesto
researchersempowersthemtorecognizeandpartakeinimportantacademicconferencesandassists
themingettingpublishedinimpactfuljournals.Avenuerecommendationsystembecomeshelpful
inthisscenario,particularlywhenexploringanewfieldorwhenfurtherchoicesarerequired.We
proposeCNAVER:AContentandNetwork-basedAcademicVEnueRecommendersystem.Itprovides
anintegratedframeworkemployingarank-basedfusionofpaper-paperpeernetwork(PPPN)model
andvenue-venuepeernetwork(VVPN)model.Itonlyrequiresthetitleandabstractofapaperto
providevenuerecommendations,thusassistingresearchersevenattheearlieststageofpaperwriting.
Italsoaddressescoldstartissuessuchastheinvolvementofaninexperiencedresearcherandanovel
venuealongwiththeproblemsofdatasparsity,diversity,andstability.ExperimentsontheDBLP
datasetexhibitthatourproposedapproachoutperformsseveralstate-of-the-artmethodsintermsof
precision,nDCG,MRR,accuracy,
F

measure
macro
,averagevenuequality,diversity,andstability.

2019ElsevierB.V.Allrightsreserved.
1.Introduction
Arecommendersystemrecommendsdifferentobjectsbased
onauserspreferencesusingvariousdataanalysistechniques[
1

3
].Academicrecommendersystemscansuggestcollaborators[
4

6
],papers[
7

11
],citations[
12

16
],and/oracademicvenues[
15
,
17

22
].Thesesystemshavebeenusefultoacademiciansasthey
objectivelyprovideuserswithpersonalizedinformation
services[
22

25
].Althoughtherehavebeenquiteafewworks
ondifferentacademicrecommendations,verylittlebodyofwork
existsintheliteratureonacademicvenuerecommendations,
albeitstartedquiteearly[
19
].
Theresearchers,ingeneral,intendtopublishinacademic
venuesthatacknowledgehigh-qualitypapersandparticipatein
academicconferencesorworkshopsthatarerelevanttotheirarea
ofresearch[
26
,
27
].Amongvariousproblemsthatresearchers
confront,animportanttaskistoidentifyappropriatepublica-
tionvenues.Thetaskisnowadaysbeingincreasinglydifficult
I
Noauthorassociatedwiththispaperhasdisclosedanypotentialor
pertinentconflictswhichmaybeperceivedtohaveimpendingconflictwith
thiswork.Forfulldisclosurestatementsreferto
https://doi.org/10.1016/j.knosys.
2019.105092
.

Correspondingauthor.
E-mailaddresses:
tpradhan.rs.cse16@itbhu.ac.in
(T.Pradhan),
spal.cse@iitbhu.ac.in
(S.Pal).
duetothecontinuousincreaseinthenumberofresearchar-
easanddynamicchangeinthescopeofjournals[
19
,
28
].More
collaborationsaretakingplaceamongdisciplinesintheresearch
communities,whichisleadingtoreducedcompartmentalization
atthecoarselevelbutacontinuousincreaseinthenumber
ofvenuesininterdisciplinaryareas[
19
,
29
].Forexample,DBLP
1
dataset,acollectionofscientificpublicationrecordsandtheir
relationshipwithinthatcollectionhas9585computerscience
conferences
2
andthenumberofjournalsismorethan4152
3
[
30
].
Astheresearchhorizonexpands,researchersfinditchalleng-
ingtoremainuptodatewithnewfindings,evenwithintheir
disciplines[
31
].Moreover,withtime,researchersinterestsex-
pand,evolve,oradaptinrapidlychangingsubjectareasneeding
informationonappropriatevenuesinthechangedscenario[
25
].
Increaseininterdisciplinaryresearchareasalsoposesgreatchal-
lengestoresearchinstitutesandtheirlibrariesastheystriveto
understandinformation-seekingbehaviorsanddynamicinforma-
tionneedsoftheusers[
19
].Informationspecialistsneedtimely
andseamlessinformationonresearchersreadingprioritiesto
makedecisionsonvenuesubscriptionsinsteadofrelyingonlyon
thevenuesimpactfactororusersexplicitrequests.
1
http://dblp.uni-trier.de/db/
2
http://dblp.uni-trier.de/db/conf/
3
http://dblp.uni-trier.de/db/journals/
https://doi.org/10.1016/j.knosys.2019.105092
0950-7051/

2019ElsevierB.V.Allrightsreserved.
/>Page 2
----------------------------------------------------------------------------------------------------<2
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
Ontheotherhand,researchersalsoneedtoknowaboutnew
venuestoremainupdated.Theyusuallygetupdatesfromcol-
leagues/supervisors,friends,internet,andbooksbutoftenthe
informationisnotsufficientlycomprehensiveand/orappropriate
astheirresearchdemands.Theresearchers,therefore,sometimes
endupapproachinginappropriatevenuesresultinginrejections,
delaysinpublicationand/orcompromiseinthequalityofthe
publication.Venuerecommendationforeitherjournalsorconfer-
ences,inparticular,has,therefore,becomeanessentialareaofre-
searchinrecenttimes[
32
].Outofmanyreasonsforitsincreasing
importance,somearegivenbelowasemergingscenarios[
22
].
(a)
Aresearcherfromtheindustryhasmadeabreakthrough
inherresearcharea.Tocollaboratewithherpeersfrom
academia,shemaywanttofindasuitableacademicvenue
(conference)thatsheisnotveryawareof.
(b)
Ajuniorresearcher,i.e.,aresearcherwhoisattheinitial
stageofherresearchandhasnoorveryfewpublica-
tions,intendstoextendherresearcharea.Butalackof
knowledgeaboutappropriateacademicvenuesbecomesa
challengeforhertoexplorenewerareas.
(c)
Aveteranresearcherknowsherresearchareaverywell,
butwhensheventuresintoanewfieldorworksinan
interdisciplinaryarea,shemaylookforacross-fieldvenue
recommendation.
(d)
Ajournalmaymergewithsomeotherrelatedjournalwith
modifiedscopesandobjectives.Theresearchersmaynot
beawareofsuchdevelopments.
Torecommendasuitablevenueofhighquality,weneedto
focusfromtheperspectiveofaresearchersneedsanddevelop-
mentoftheparticularresearchareainquestiononthefollowing
issues.
(i)
Whatarethemostrelevantvenuesofpublicationsfora
researcherinquestion?
(ii)
Howcanaresearcherfindhigh-qualityvenues?
(iii)
Whatarethemostsuitableconferences/workshopsare-
searchershouldparticipatein,foragivenarea?
Mostoftheexistingtechniquesdependonco-authorspastpub-
licationsand/orratingsofthevenuesprovidedbyotherre-
searcherstoperformsuchavenuerecommendation.Afewap-
proachesusearandomwalkmodel,topic-basedsimilarityforthe
same.Basedonourliteraturesurvey,weattempttoexplorethe
followingresearchquestions(RQs).
RQ1:
Towhatextenttheexistingcollaborativefiltering(CF)
basedmodelscanrecommendsuitablevenuesfromthe
perspectiveofaresearchersneeds?
RQ2:
Canthecurrentcontent-basedfiltering(CBF)approaches
recommendsuitablevenuesfromtheperspectiveofare-
searchersneeds?
RQ3:
Isthereanyissueswiththenetwork-based(NB)recom-
mendationmodelonvenuerecommendation?
RQ4:
Towhatextentdotheexistingapproacheshandlecold-
startproblemslikenewresearchers,newvenues,andother
issuessuchasdatasparsity,diversity,andstability,etc.?
Severalissueswiththeexistingstate-of-the-arttechniqueshave
beenreportedintheliterature.Forexample,content-basedand
network-basedsimilaritytechniquesutilizeonlyasingleas-
pectofeithercontentorcitationsfromscientificpapers,respec-
tively[
9
,
33
].Veryfewattemptshavebeenmadethatconsidered
bothcontentandnetwork,especiallyinthedomainofvenue
recommendation.Tobridgethisgap,wewouldliketoproposea
hybridmethodCNAVER:Animprovedcontent-basedfilteringand
improvednetwork-basedfusionmodeltoprovideapersonalized
academicvenuerecommendersystem.
CNAVERisbuiltontwomajorcomponentsthatcontribute
inparallel,butfinally,theircontributionsarefusedtogetherto
presentacoherentvenuerecommendation.Oneisthepaper-
paperpeernetwork(PPPN)modelandtheothervenue-venue
peernetwork(VVPN)model.WhilePPPNexplorestheinteraction
amongpaperstowardsvenuerecommendation,VVPNactually
studiesitamongpublicationvenues.
Keycontributionsofthisworkarethefollowings:

Todealwith``cold-start
4
issueslikeanewresearcherand
anewvenue,PPPNandVVPNmodelsarefusedtoprovide
apersonalizedvenuerecommendersystem.CNAVERworks
irrespectiveofresearcherspastpublicationrecords,instead
onlyfocusesontheworkathand.Newvenueswithno
citationsavailablearealsoconsideredforabstractsimilarity.
Newvenuesarealsogivenanequalchanceforinclusionin
thefinalrecommendation.

Toaddress``datasparsity
5
issuescitationnetworkisused
toexaminetheimportanceofeachcandidatepaperthrough
thecumulativescoresofcentralitymeasuressuchasdegree,
betweenness,andcloseness,etc.Lateron,contextualsimi-
laritysuchasLDAonabstractandDoc2Veconthetitleare
performedtoreducethebibliographicnetworksizeandalso
toincreasetherelatednessamongpapers.

Toresolvetheissueof``diversity
6
afusionmodelincor-
poratingbothPPPNandVVPNmodelareproposed.Specifi-
cally,age-discounted(age-discounted)basedVenue2Vec,
meta-pathfeatures,andbiasedrandomwalkareincorpo-
ratedintotheNBmodeltorecommendvenuesfromdiverse
publishers.TheproposedsystemCNAVERcanprovidea
``diversifiedrecommendation.Ittakesintoaccountboth
journalsandtoptierconferencesfrommultiplepublishers
likeElsevier,Springer,IEEE,ACM,andothers.

Toaddresstheissueof``stability,
7
afusionmodelCNAVER
incorporatingbothPPPNandVVPNmodelsareproposed.
Anynetwork-basedapproachisknowntocauseinstability
intherankswithtimeastheintroductionofnewnodesor
edgeschangethetopologyandtherebychangerecommen-
dations[
34
].Wethereforealsotookintoaccountcontent-
basedapproachesatseveralstageswithinbothPPPNand
VVPNpipeline.Aseparatestudyonstabilityprovedthatit
workedandourswasthemoststablesystem,morethanthe
existingones.

Comprehensiveexperimentswereconductedusingareal-
worlddataset,i.e.,DBLPtoevaluatetheperformance
oftheproposedsystemCNAVER.Theproposedsystem
outperformsseveralotherstate-of-the-artvenuerecom-
mendationmodelswithsubstantialimprovementsinpreci-
sion@k,nDCG@k,MRR,accuracy,
F

measure
macro
,average
venue-quality(ave-quality),diversityandstability.
Thispaperisorganizedasfollows.Wevisittherelatedlitera-
tureinSection
2
.WeprovidemotivationinSection
3
andthen
moreelaborateproblemdescriptioninSection
4
.Descriptionof
differentfeaturesweadoptedinourrecommendationframework
isprovidedinSection
5
,datapreprocessingstepsaredescribed
inSection
6
,contextualsimilaritycalculationsareshowninSec-
tion
7
,descriptionofpeer-peernetworkmodelsaredepictedin
Section
8
andfusionmodelisillustratedinSection
9
.Experimen-
taldetailsareillustratedinSection
10
.Wereportexperimen-
talresultsandinsightfuldiscussionsareinSections
11
and
12
respectively.WefinallyconcludeinSection
13
.
4
Coldstartissuesmainlyindicatethenewresearchersandnewvenuesin
academia.
5
Sparsitydenotesaveragedistanceamongpairsofrelatedpapers.
6
Diversitymeanshowmanydifferentvenuesarerecommended.
7
Stabilitydenotesresiliencetochangeinrankedrecommendationswiththe
introductionofnewpapers.
/>Page 3
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
3
2.Relatedwork
AdomaviciusandTuzhilin[
2
]authoredacomprehensivere-
viewofrecommendersystemsandsuggestedmainlythreetypes
ofrecommendersystemsbasedontheirworkingprinciples.In
addition,wealsoincludenetwork-basedrecommendation[
22
].
Weattempttoprovideherenecessarybackgroundintheaca-
demicrecommendersystemsaccordingtotheirtaxonomy.
2.1.Collaborativefilteringbasedrecommendation(CF)
Collaborativerecommendersystems(orcollaborativefiltering
systems)predicttheutilityofitemsforauserbasedonthe
itemspreviouslyratedbyotheruserswhohavesimilarlikings
ortastes[
2
].Inthefieldofacademicrecommendations,Yang
etal.[
35
]proposedamodeltoexploretherelationshipbetween
publicationvenuesandwritingstylesusingthreekindsofstylo-
metricfeatures:lexical,syntacticandstructural.Inanotherpaper,
Yangetal.[
36
]usedacollaborativefilteringmodelincorporating
writingstyleandtopicinformationofpaperstorecommend
venues.Yangetal.[
15
]proposedanotherjointmulti-relational
model(JMRM)ofvenuerecommendationforauthor-paperpairs.
Hyunhetal.[
37
]proposedacollaborativeknowledgemodel
(CKM)toorganizecollaborativerelationshipsamongresearchers.
Themodelquantifiedthecollaborativedistance,thesimilarityof
actorsbeforerecommendations.Yuetal.[
38
]proposedapre-
dictionmodelthatusedcollaborativefilteringforapersonalized
academicrecommendationbasedonthecontinuityfeatureofa
usersbrowsingcontent.Liangetal.[
1
]proposedaprobabilistic
approachconsolidatinguserexposurethatwasmodeledasa
latentvariable,inducingitsincentivefromdataforcollaborative
filtering.Alhoorietal.[
19
]recommendedscholarlyvenuestaking
intoaccounttheresearchersreadingbehaviorbasedonpersonal
referencesandthetemporalfactorofwhenreferenceswere
added.Trappeyetal.[
39
]presentedanewpatentrecommen-
dationsystembasedonclustersofusershavingsimilarpatent
searchbehaviors.
2.2.Content-basedfilteringbasedrecommendation(CBF)
InCBF,usersarerecommendeditemssimilartotheones
theuserpreferredinthepast.Kochenetal.[
40
]proposeda
methodtorecommendjournalsforauthorsmanuscriptsbased
onrelevance,acceptancerate,andprestigeofjournals.Medvet
etal.[
20
]consideredthetitleandabstractofpaperstorecom-
mendscholarlyvenuesconsidering
n
-grambasedCanvar-Trenkle,
two-steps-LDA,andLDA
C
clusteringtoretrievelanguageprofile,
asubtopicofpapers,andidentificationofthemaintopicasa
researchfield.
Erramietal.[
41
]proposedamodelcalledeTBLASTtorecom-
mendjournalsbasedonabstractsimilarityusingthez-scoreof
asetofextractedkeywordsandweightedformulaof``Journal
score.Schurmieetal.[
42
]proposedtheJournal/AuthorName
Estimator(Jane)
8
onbiomedicaldatabaseMEDLINEtorecom-
mendjournalsbasedonabstractsimilarity.Theyexploiteda
weighted
k
-nearestneighborsandLucenesimilarityscoretorank
articles.Similarly,Wangetal.[
9
]presentedacontent-basedpub-
licationrecommendersystem(PRS)oncomputerscienceexploit-
ingsoft-maxregressionandchi-squarebasedfeatureselection
techniques.
Recently,fewonlineserviceshavestartedprovidingsup-
portforsuggestingjournalsusingkeywords,title,andabstract
matching.TheseservicesincludeElsevierJournalFinder
9
[
43
],
8
http://jane.biosemantics.org
9
http://journalfinder.elsevier.com
SpringerJournalSuggester,
10
EdanzJournalSelector
11
andEnd-
NoteManuscriptMatcher
12
etc.ElsevierJournalFinderrequires
onlythetitleandabstractofapaperandusesnounphrasesas
featuresandOkapiBM25
C
torecommendjournals.But,recom-
mendationsarerestrictedtoElsevierpublishersonly[
43
].
2.3.Network-basedrecommendation(NB)
Ontopoftheaboveapproaches,theapproachbasedona
networkrepresentationoftheinputdatahasgainedconsiderable
attentionintherecentpast.Here,asocialgraphisbuiltamong
theauthorsbasedonco-authorship.Anedgeexistsbetweentwo
authorsiftheyco-authoratleastonepaper[
21
,
44
].Thevenue
havingthehighestcountamongthepaperswithin
n
-hopsfroma
givenauthor-nodeisrecommended.Klammaetal.[
32
]proposed
aSocialNetworkAnalysis(SNA)basedmethodusingcollabora-
tivefilteringtorecognizemostsimilarresearchersandrankob-
scureeventsbyintegratingtheratingofmostsimilarresearchers
fortherecommendations.Silvaetal.[
45
]proposedathree-
dimensionalresearchanalyticsframework(RAF),incorporating
relevance,productivity,andconnectivityparameters.
Phametal.[
46
]usedthenumberofpapersofaresearcher
inavenuetodetermineherratingforthatvenueusingthe
clustersonsocialnetworks.Later,Phametal.[
47
]presented
clusteringtechniquesonasocialnetworkofresearcherstoiden-
tifycommunitiestogeneratevenuerecommendations.Theyalso
appliedtraditionalCFcalculationstoprovidethesuggestions.
Chenetal.[
28
]introducedamodelAVERtorecommendthe
scholarlyvenuestoatargetresearcher.Thisapproachutilizesa
randomwalkwithrestart(RWR)modelontheco-publication
networkincorporatingauthor-authorandauthor-venuerelations.
Later,Yuetal.[
22
]extendedAVERtopersonalizedacademic
venuerecommendationmodelPAVEwherethetopicdistribution
ofresearcherspublicationsandvenueswereutilizedinLDA.
Luongetal.[
48
]identifiedsuitablepublicationvenuesby
investigatingtheco-authorshipnetwork,mostfrequentconfer-
ences,normalizedscoresbasedonmostsuccessiveconferences.
Luongetal.[
21
]inanotherworkrecommendedsuitablepubli-
cationvenuesbyinvestigatingauthorsco-authorshipnetworks
inasimilarfield.Xiaetal.[
18
]providedvenuerecommenda-
tionsusingPearsoncorrelationandcharacteristicsocialinfor-
mationofconferenceparticipantstoenhancesmartconference
participation.
2.4.Hybridrecommendation(HR)
Hybridapproachescombinecollaborativeandcontent-based
methodsavoidingcertainlimitationsofcontent-basedandcol-
laborativesystems.Wangetal.[
9
]proposedhybridarticlerec-
ommendationsincorporatingsocialtagandfriendinformation.
Boukhrisetal.[
49
]suggestedahybridvenuerecommendation
basedonthevenuesoftheco-citers,co-affiliatedresearchers,
theco-authorsofthetargetresearcher.Itisbasedonbiblio-
graphicdatawithcitationrelationshipsbetweenpapers.Minkov
etal.[
50
]introducedamethodofrecommendingfutureevents.
Tangetal.[
4
]introducedacross-domaintopiclearning(CTL)
modeltorankandrecommendpotentialcross-domaincollabo-
rators.Xiaetal.[
18
]proposedasociallyawarerecommenda-
tionsystemforconferences.Similarly,Cohenetal.[
5
]explored
thedomainofmining-specificcontextinasocialnetworkto
recommendcollaborators.
10
http://journalfinder.com
11
https://www.edanzediting.com/journal-selector
12
http://endnote.com/product-details/manuscript-matcher
/>Page 4
----------------------------------------------------------------------------------------------------<4
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
3.Motivation
Althoughthetechniquesdiscussedabovedoproviderecom-
mendationsreasonablywell,theysufferfromalotofissues.
Belowwediscusstheproblemsthatledustoinvestigatefurther
inconnectiontoourstatedresearchquestions(RQs)aspresented
inSection
1
.
3.1.ProblemswithCFapproach(RQ1)
AlthoughCFhasbeenquitepopularinthelastdecadefor
scholarlyvenuerecommendation,mostofthemsufferfromthe
followingdrawbacks.
(i)
CFapproachesarelesseffectivewhentherearenotenough
ratingspresentintheresearcher-venuematrix.Therec-
ommendationsmaynotbeusefulinthecaseofanew
researcherwholackspublicationhistory.
(ii)
Thetechniquesarenotlikelytorecommendanewvenue
oralesspopularvenueasthevenuelacksinpublication
statistics.Therefore,somerelevantvenuesmaybemissed.
(iii)
Computationalcostishighbecauseofanextensivenumber
ofarticles,venues,andresearchersinvolvedaretakeninto
considerationduringprocessing,andthus,scalabilityisa
challenge.
(iv)
Researcher-venuematrixthatisatthecoreofthetech-
niquesisexceptionallysparseasmostoftheresearchers
publishandciteafewarticlesandareinvolvedwithvery
fewacademicvenues.
3.2.ProblemswithCBFapproach(RQ2)
CBFortopic-basedmodelsusetheauthorsprofile,thecontent
oftheirpapersaswellasthatofthepaperspublishedataspecific
venue[
51
].MostapproachesuseLDAfortopicmodelingandrank
venuesbasedonthesimilarityofvenuesthatpublishedsimilar
papers[
21
].But,ininformationretrieval,longerdocumentsget
anadvantageduringthecomputationofquery-documentsimilar-
ityovertheirshortercounterparts[
52
].Othersalientissueswith
CBFapproachesareasfollows.
(i)
CBFapproachessufferfromlimitedcontentanalysis,which
cansignificantlyreducethequalityofrecommendation[
9
,
33
].Mostofthetime,theyrequirethefulltextofthe
paperandthus,arenotusableattheearlystageofpaper-
writing[
20
].Usually,theabstractisnotsufficienttoextract
thenecessaryreliableandrelevantinformation.
(ii)
Newvenuesarelesslikelytoberecommendedasthemod-
elsprefervenueswithahighnumberofpaperspublished
therein.
(iii)
Themodelsprovideapoorrecommendationtoanew
researcherwholackspublicationrecords.
(iv)
Therecommendationsareheavilybiasedtowardsthepast
areaofresearchofaresearcherandthereforenotsuitable
whenonechangesherareaofinterestorworksinan
interdisciplinaryfield.
3.3.ProblemswithNBapproach(RQ3)
ToalleviatetheproblemoflimitedcontentanalysisinCBF
andthecold-startissueoccursinCFapproachesoflate,network-
basedapproach(NB)orco-authorbasedapproachhasbeenpro-
posed[
7
,
22
,
28
,
45
,
47
,
48
].Inthismodel,asocialgraphisbuilt
amongtheauthorsinlightofco-authorship[
15
,
46
].Anedge
existsbetweenresearchersiftheyco-authornolessthanone
paper[
8
,
21
].Acoupleofworksconsiderarandomwalkwith
restart[
22
,
28
].Thevenuehavingthehighestcountamongthe
paperswithin
n
-hopsfromtheauthor-nodeisrecommended.A
fewlimitationsoftheapproachesareasfollows.
Table1
TypeofverticesusedinHIN.
No.Verticestype
1
P
_
main
Df
setofpapersthatbelongingtoaparticularvenue
g
2
P
_
ref
Df
setofpapersthatcitedbya
P
_
main
paper
g
3
P
_
cite
Df
setofpapersthatcitesa
P
_
main
paper
g
4
A
(
author
)
Df
authorofanytypeofpaper(
P
_
main
,
P
_
cite
;
P
_
ref
)
g
5
T
(
term
)
Df
termappearingintitlesorabstractsofa
P
_
main
paper
g
6
V
(
v
enue
)
Df
setofanyvenuewhere
P
_
main
typepaperspublished
g
(i)
Irrespectiveofactualcontent,eachpaperauthoredbythe
samesetofauthorswillreceivethesamerecommendation.
(ii)
Recommendationsareverypoorforanewresearcherwho
doesnothaveanypastpublicationrecords.
(iii)
Itcannotrecommendanewvenueasthemodelisbased
onthepublicationhistoryofvenues.
(iv)
Venueswithlesspopularityamongtheco-authorsofa
givenauthorareseldomrecommended,althoughcontent-
wisetheymaybeappropriate.
3.4.Cold-startissuespresentintheexistingapproach(RQ4)
Mostoftheapproachesdiscussedabovesufferfromvarious
coldstartissuesfornewresearchers,newvenues,orlesspopular
venuesandalsootherproblemslikedatasparsity,scalability,
diversity,andstability,etc.Afewlimitationsoftheexisting
approachesareasfollows.
(i)
IntheCF-basedvenuerecommendersystem,datasparsity
isamajorissuethatarisesduetothesparsenessofthe
matrixofresearcher-venueratings.Italsosuffersfromthe
cold-startproblemfornewresearchers.
(ii)
CBFperformspoorlyduetoambiguityintextcomparison
andalsosuffersfromcoldstartissuesofnewresearchers
andnewvenues.
(iii)
TwomajorissuesofCBFapproachesarelimitedcontent
analysisandover-specialization,andduetowhich,thelack
ofdiversityisasevereprobleminthistypeofapproach[
3
,
9
,
33
].
(iv)
ScalabilityisalsoamajorchallengeinCFandCBFbased
venuerecommendersystemsasproceduresthereinarenot
linearininput-size.
(v)
Mostofthetime,stabilityisasevereissueinCFandNB
basedvenuerecommendersystems.
(vi)
Theexistingtechniqueshaveanunduebiasagainstthe
newvenuesandnewresearcherscomingintothesystem
withfewerpublicationrecords[
21
,
41
,
47
].
4.Problemdescriptionandotherdefinitions
Definition1.
HeterogeneousInformationNetwork(HIN)[
53
,
54
].
ItisdefinedasadirectedgraphG=(
N
;
L
)withanodetype
mappingfunction

:
N
!
W
andalinktypemappingfunction

V
L
!
Y
.Eachnoden
2
N
belongstooneparticularnodetype
inthenodetypeset
W
:

(n)
2
N
,andeachlinkl
2
L
belongsto
aparticularlinktypeinthelinktypeset
Y
:

(l)
2
L
.Herethe
typesofnodes
j
W
j
>
1andthetypeoflinks
j
Y
j
>
1.
Example.
In
Fig.
1
,wehavesixtypesofvertices,suchthat
W
D
{
P
_
main
,
P
_
ref
,
P
_
cite
,
A
,
T
,
V
}andsixtypesofedges
Y
.The
meaningofeachtypeofverticesispresentedin
Table
1
.In
Fig.
1
,
a
P
_
main
paperiseitherthepaperwithinthesetofvenue
v
i
or
venue
v
j
andcategorizedasmainpaper.Both
P
_
cite
and
P
_
ref
are
consideredasnon-mainpapersandcouldbeassociatedwithany
venues.Similarly,themeaningofeachtypeofedgesisdefinedin
Table
2
.
/>Page 5
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
5
Fig.1.
GraphicalrepresentationofHINgraph.
P
_
main
paperisanyPbelongsto
eitheronethedisparatevenuesandlatentmetapathsbetween
P
_
main
papers
maybeformedviavariousverticestypes:citedby
P
_
main
(
P
_
ref
),citesa
P
_
main
(
P
_
cite
),
author
(
A
),
term
(
T
),and
v
enue
(
V
).
Definition2.
Venue-VenueGraph(VVG).Let
G
0
D
(
V
0
;
E
0
)be
thenewlygeneratedvenue-venuegraph(VVG)fromHINbased
onthesimilarityscoreofabstractandtitle.
V
0
Df
v
1
;v
2
;:::;v
l
g
.
Eachedge
e
D
(
v
i
;v
j
)
2
E
0
representsacurrentlysimilarresearch
scopeof
v
i
with
v
j
basedontheirpastpublications.Anedge
e
D
(
v
i
;v
j
)
2
E
0
existsifthesimilarityscorebetweenvenues
v
i
and
v
j
isgreaterthanaveragesimilarityscore.Weweighttheedgesof
thenetwork
VVG
usingcontentsimilarity(linearcombinationof
abstractandtitle)inordertoprovideasinglescoreasexplained
inSection
8.2.2
.
Definition3.
Meta-path[
55
].Ameta-path
M
isapathdefined
ontheHINgraph.Itjoinstwoormoreverticesusingoneormore
edgessuchthat
M
D
n
1
l
1
!
n
2
l
2
!
l
t
!
n
t
C
1
,wherethestarting
andendingverticesareofsamevertextype
P
_
main
,

(
n
1
)
D

(
n
t
C
1
)andbothbelongto
P
_
main
,
P
_
main
2
W
,

(
l
1
;
l
2
;:::;
l
t
)
2
Y
.
Example.
In
Fig.
1
,Therewillbeametapathbetweenvenue
v
i
andvenue
v
j
viathemetapathVenue
v
i
publish
!
P
_
main
citedby
!
P
_
cite
cites
!
P
_
main
publishedby
!
Venue
v
j
.
Definition4.
RandomWalk[
56
].Arandomwalkisdefinedas
anodesequence
S
r
Df
v
1
;v
2
;v
3
;:::;v
l
g
whereinthe
i
thnode
v
i
1
inthewalkisrandomlyselectedfromtheneighborsofits
predecessor
v
i
2
.
Definition5.
CitationNetwork.Let
G
D
(
V
;
E
)bethecitation
graph,with
n
papers.
V
Df
p
1
;
p
2
;:::;
p
n
g
.In
G
,eachdirected
edge
e
D
(
p
i
;
p
j
)
2
E
representsacitationfrom
p
i
to
p
j
.
Example.
Weusethefollowingtwophrasestodescribethe
citationnetwork.
Fig.2.
ThebasicblockdiagramofCNAVER.
Table2
TypeofedgesusedinHIN.
No.Edgestype
1
n
1
w
ritten
_
by
!
n
2
V

(
n
1
)
2
f
P
_
main
;
P
_
ref
;
P
_
cite
g
;
(
n
2
)
D
A
;
n
1
;
n
2
2
N
2
n
1
contains
!
n
2
V

(
n
1
)
2
f
P
_
main
;
P
_
ref
;
P
_
cite
g
;
(
n
2
)
D
T
;
n
1
;
n
2
2
N
3
n
1
cites
!
n
2
V

(
n
1
)
2
P
_
main
;
(
n
2
)
D
P
_
ref
;
n
1
;
n
2
2
N
4
n
1
cited
_
by
!
n
2
V

(
n
1
)
2
P
_
main
;
(
n
2
)
D
P
_
cite
;
n
1
;
n
2
2
N
5
n
1
cites
!
n
2
V

(
n
1
)
2
P
_
main
;
(
n
2
)
D
P
_
main
;
n
1
;
n
2
2
N
6
n
1
cited
_
by
!
n
2
V

(
n
1
)
2
P
_
main
;
(
n
2
)
D
P
_
main
;
n
1
;
n
2
2
N
(i)
Referencesof
p
i
representthesetofpaperswhichare
referredbythepaper
p
i
.
(ii)
Citationto
p
j
denotesthecollectionofpaperswhichhave
usedthepaper
p
j
asareference.
Therestofthepaper,weusetheabovetwophrasestodescribe
thegrapharoundvertex
p
i
.
Definition6.
VenueRecommendation.Leteachpaper
p
i
pub-
lishedinaparticularvenue
v
i
.Sonowwehave,
B
Df
v
1
;v
2
;:::;v
l
g
beapredefinedsetofpublicationvenues.
Givenainputpaper(seedpaper)
p
m
,thevenuerecommendation
taskistorecommendalistofsuitablepublicationvenues(
v
1
,
v
2
;:::;v
N
)relatedtotheseedpaper
p
m
,wherethelistisordered
fromthemostrelevanttotheleastrelevant.
Example.
Itisessentiallyarankingproblem.Weneedtodeter-
minethesetofpaperswhicharecloselyrelatedtotheseedpaper.
Venuerecommendationsareprovidedifthetitleandabstractof
aseedpaperaregiventothesystemasinput.Theblockdiagram
isdepictedin
Fig.
2
.
5.ArchitectureofCNAVER
Wepresentanoverallarchitectureoftheproposedframework
alongsideitsoperationalstrategies.Ourgoalistoexhibitwhya
fusionmodelwithastep-insightfullayeredapproachhasbeen
chosenasopposedtoaflatarchitecturecontainingasetof
components.Asthebibliographicdatasetisexceptionallymassive
insize(2,408,010papers),ifweattempttorecognizethetop-
mostsimilarpapersforeachseedpaperbylookingatcontextual
similarityagainsttheentiredataset,theoverallcomputational
overheadwillbehigh.
5.1.FrameworkofCNAVER
Weproposeasystemcomprisedoftwoblocks:Block-Iand
Block-IIasdepictedin
Fig.
3
.Toreducecomputationaloverhead
/>Page 6
----------------------------------------------------------------------------------------------------<6
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
andtomakeitindependentandautonomousofseedpapers,
particularlyBlock-I,isdevelopedonceforthewholecitation
network.Lateron,wewillutilizetheseedpaperinputtointeract
withBlock-IItoextractmeaningfulrecommendationsfromboth
thePPPNmodelandVVPNmodel.
Wepresentalayeredarchitecturewhereeachlayerrealizes
aspecializedtask.Thesystemconsistingoffouressentiallay-
ers,whereLayer-1toLayer-3belongtoBlock-I,andLayer-4to
Block-II.
Fourprimarylayersareportrayedasgivenunderneath:
(i)
Datapreprocessingandcentralitycalculation(
Layer-1
):
Thislayeraimstostructurethedatasetintoaformalmodel
forprocessing.Mainlyitisusedforfasterextractionofrel-
evantpapersandtheimportanceofeachcandidatepapers
forfurtheruse(
BlockI
).
(ii)
Contextualsimilaritycalculation(
Layer-2
):Thislayercan
alsobecalledthefeatureextractionlayerandismainly
introducedtoextractrequiredcontextualfeaturesneeded
tocomputePaper2VecinPPPNmodelandVenue2Vecin
VVPNmodel.Itisalsousedtofilteronlypotentiallyuseful
papersfromSet-II,basedoncontentsimilarity(
BlockI
).
(iii)
Peer-peernetworkmodel(
Layer-3
):Thislayerusesapeer-
peernetworktoprocessthedataandtomakearecommen-
dation.Theobjectiveofthislayeristoreducecomputa-
tionaloverheadandtomakeitindependentofseedpapers
(
BlockI
).
Thislayercomprisesoftwodistinctmodels,namely:
(a)
PPPNmodel:Themainobjectiveistocapturethe
strengthofindividualpapersandtheircitationre-
lationshipwithotherpapersinacitationnetworkto
obtainrelevantvenuestotheseedpaper.
(b)
VVPNmodel:Themainideabehindthismodelisto
capturethesimilarity(indirectrelationshipamong
venuesviameta-pathanalysis)amongvenuesina
heterogeneousbibliographicnetworktoobtainrele-
vantvenuestotheseedpaper.
(iv)
Fusionmodel(
Layer-4
):Toprovideadiversifiedperson-
alizedrecommendation,thePPPN,andVVPNmodelsare
utilizedtomakepredictionsindividuallyandlaterona
fusionmodelfirstlyisappliedtointegratethestrengthsof
boththemodelsandtoreducetheirweaknesses(
BlockII
).
6.Datapreprocessingandcentralitycalculation(Layer-1)
Initially,therewere3,079,007rowsand7columnsinthe
combineddataset.Afterremovingduplicatepapers,paperswith
missingfieldsinthedatabase,etc.,weareleftwith2,236,968pa-
pers.Wealsodroppapershavingfieldsfilledupwithinconsistent
entries.Wealsoignorenon-textualcontentfromtheabstracts
ofthepapers.ThedetailedstatisticsoftheDBLPdatacollection
aredescribedinSection
10.1
.Allsuchpapersarecheckedfor
theirreferencessection.Weseparatelytreatthepapershaving
referencesornot.
(i)
Thesetofpaperswherereferencesareavailablearecalled
Set-I.
(ii)
ThesetofpaperswithoutreferencesarecalledSet-II.
WegenerateacitationnetworkonlywiththeSet-Ipapers.
Amongthecentralitymeasures,weusedegree,betweennessand
closenessmeasures(definedbelow)amongsuchpapers[
57
,
58
].
6.1.Degreecentrality(C
D
)
Inagraph,thedegreeofanodeisthenumberofedgesthat
areadjacenttothatnode[
59
].Higherthenumberofneighbors
ofagivennode,thehigheritsimpactis.Degreecentralityofa
paper
p
isdefinedas
C
D
(
p
)
D
indeg
(
p
)
C
outdeg
(
p
)
(1)
where
indeg
(
p
)isthenumberofresearcharticlesorpapersciting
topaper
p
and
outdeg
(
p
)isthenumberofpapers
p
isreferringto.
Foreachpaper
p
,in-degree(
p
)iscomputed.Thepaperswhose
in-degreeisgreaterthanorequaltoaveragein-degreeofthe
networkareshortlistedforfurthercomputation.Lateronagain,
theaveragescoreofdegree{indeg(
p
)
C
outdeg(
p
)}istaken
intoconsiderationforremovingpapers.Weadoptsuchtwo-stage
filteringinordertoensurethat:(i)first,highlycitedpapersare
notmissedand(ii)nonewpaperswhichcitealotofpapersare
missedeither.
6.2.Betweennesscentrality(C
B
)
C
B
ofanodequantifieshowfrequentlythenodeshowsupon
differentpossibleshortestpathsbetweenanytwogivennodes.
Here
C
B
ofapaper
q
isdefinedas
C
B
(
q
)
D
X
p
;
k
;
q
2
V
p
6D
k
6D
q

pk
(
q
)

pk
(2)
where

pk
denotethenumberofshortestpathsfrom
p
to
k
and

pk
(
q
)denotethenumberofshortestpathsfrom
p
to
k
via
q
.
Nodeswithhighbetweennessactaspotentialdealmak-
ers[
60
].
6.3.Closenesscentrality(C
C
)
Themetricattemptstocapturehowcentrallyanodeislocated
vis-a-visothernodesandismeasuredastheinverseoftotal
pair-wisedistancesfromthenodetoallothernodes.Closeness
centralityofanode
p
isdefinedas
C
C
(
p
)
D
1
P
q
6D
p
p
2
V
d
G
(
p
;
q
)
(3)
where
d
G
(
p
;
q
)denotesthedistancebetweenvertices
p
and
q
,
i.e.theminimumlengthofanypathconnecting
p
and
q
in
G
.
Wehavepresentedasummaryoftheimportanceofvarious
centralitymeasuresusedinthispaperin
Table
3
.Weusethe
abovethreemeasurestoshortlistasetofcandidatepapersfor
Layer-2(Contextualsimilaritycalculation).Theaveragescoreof
eachmeasureisusedasathresholdtofilterimportantpapers
fromeachcategory.Initially,weremovepaperswithlessthan
average
indeg
astheyarenotcitedbymanyandhenceless
influential.Afterfilteringpaperswithlowin-degree,paperswith
degree
scoregreaterthanorequaltoaveragedegreescoresare
finallyshortlistedforfurthercomputation.Thesetsweredeter-
minedindividuallyandmergedasaset-baseduniontoconsider
justtheuniquepapers.
Forexample,ifaveryhigh-qualitypaperhaslowin-degree
becauseofitsrecentpublication,thepapermaynotbeconsidered
indegreecentralitycalculation,butitgetsdueconsiderationin
Betweenness,andClosenesscentralitycalculationand,therefore,
mayqualifybasedonthesemeasures.Thiswayifapaperlacksin
oneormorefactorsinthecitationprofile,itcanqualifythrough
othercentralitymeasuresimplyingafairchancetoallpotential
papers.
/>Page 7
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
7
Fig.3.
ArchitectureofCNAVER.
Table3
Interpretationofvariouscentralitymeasures.
MeasuresInterpretationincitationnetworks
DegreeHowmanypaperscanthisarticlereachdirectly?
BetweennessHowlikelyisthispaperstobethemostdirectroutebetweentwopapersin
thecitationnetwork?
ClosenessHowfastcanthispaperreacheveryoneinthecitationnetwork?
/>Page 8
----------------------------------------------------------------------------------------------------<8
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
7.Contextualsimilaritycalculation(Layer-2)
Inthismodule,wemainlyextractcontent-basedfeaturesto
prunethesetofpapersshortlistedinLayer-1further.Sometimes
itisquitechallengingtoobservethesimilarityamongpapersby
lookingatonlythewordlevelsimilarities.Eventherearecases
wherethesemanticmeaningofwordsisunabletocapturethe
similarityamongpaperswheretheuseofwordsincontextalso
needstobeseen.Hence,weneedsomemechanismspecifically
tocapturethesemanticmeaning,todiscoverthehiddenpatterns
andtoextractthelatenttopicsotherthanjustidentifyingwords
matching.Inthispaper,weappliedLDAonabstractandDoc2Vec
onthetitletoaddresstheseaboveissues.
Anabstracttypicallyprovidesasummarycontainingthemain
ideaofapaper.WeusetheLDAmodelontheabstracttogen-
eratethefeaturedescription[
61
].LDAisusedtoidentifytopics
automaticallyandtoderivehiddenpatternsexhibitedbyatext
corpus.WehavechosenLDAoverothermethodsduetoits
simplicity,easinessinimplementation,fastcomputation,ability
todiscovercoherenttopicsandalsotohandlediversetopicsina
textcorpus.Wesetthenumberofthetopicasparameter
k
while
miningapaperstopicdistributiontoperformLDA.Itisusedas
itgeneratestheprobabilitydistributionofwordsanddocuments
basedontheco-occurrenceofwordsanddocuments,whichfocus
ondescribingtheirconnotativetopics.
WealsotriedLDAonthetitle,butduetoinsufficientterms
presentintitles,itdidnotperformwelltodiscoverhidden
patterns.Hence,Doc2Vecisusedtoextractthefeaturedescrip-
tionfromthetitleofapaperasDoc2Veccapturescontextual
informationofwordsoccurringintitles[
62
].Itismainlyusedto
generatesentence/documentembeddings[
63
].Itischosenover
othermethodsduetoitspotentialtoovercometheweaknesses
suchastheorderingofwords,thesemanticsofthewords,data
sparsity,andhighdimensionalityinbag-of-wordsmodelsand
otherapproaches.WehaveusedDoc2Veconthetitlebutnot
onabstractbecauseitwasfoundalittlebitexpensivetorepre-
senteachdocumentbyadensevectorthatistrainedtopredict
surroundingwordsincontextssampledfromthedocument.
8.Peer-peernetworkmodel(Layer3)
Featuressoextractedfromabstractandtitlearefusedinthe
nextlayertocompute:
(i)
Paper2VecinPPPNmodel
:InPPPNmodel,wewouldlike
toexploreidentifyingsuitablevenuesthroughpaper-paper
peernetworkbyexploitingtheconceptofPaper2Vecap-
proachwithouttheage-discountedscheme.
(ii)
Venue2VecinVVPNmodel
:InVVPNmodel,wewouldlike
toseethequalityoftherecommendationbyincorporat-
ingvenue-venuepeernetworkthroughtheconceptof
Venue2Vecapproach.
8.1.ThearchitectureofPPPNmodel
Duetoinformationoverload,itisnotpracticaltocheckfull
contentsimilaritytorecognizerelatedpaperswiththeseedpa-
per.Toaddressthisissue,weareattemptingtodiscoverin-
herentcommunitystructuresinabibliographiccitationnetwork
tounderstandthenetworkmoredeeplyandrevealinteresting
relationsamongthepapers.
TheprocessofPPPNmodelmainlyinvolvesfoursteps:(i)
Paper2Vecfeatureextraction,(ii)Citationnetworkpartitioning,
(iii)Topic-orientedintra-graphclustering,(iv)Abstractsimilarity
usingOkapiBM25
C
algorithm.
8.1.1.Paper2vecfeatureextraction
TheresultsfromLDAandDoc2Veccanbeconsideredastwo
setsofvectors.Foreachpaper
p
i
,wegetavector
A
i
forabstract
similarityandvector
T
i
fortitlesimilarity.Thelengthofthevector
istakenassize
k
.Wearecomputingthevectorsforbothabstract
andtitleonlyonceandlateron;wewillutilizethosevectors
tocalculatethesimilaritywithseedpapers.Toavoidrepetitive
computation,afixed-lengthvectorisconsideredinthispaper.
A
p
i
DT
a
1
i
;
a
2
i
;:::;
a
ki
U
(4)
T
p
i
DT
t
1
i
;
t
2
i
;:::;
t
ki
U
(5)
Using
A
p
i
and
T
p
i
forapaper
p
i
,wecomputecosinesimilaritywith
theircounterpartfromtheseedpaper(
p
j
).
Sim
_
abstract
(
p
i
;
p
j
)
D
A
p
i
:
A
p
j
j
A
p
i
jj
A
p
j
j
D
P
k
b
D
1
(
a
bi

a
bj
)
q
P
k
b
D
1
a
2
bi

q
P
k
b
D
1
a
2
bj
(6)
Sim
_
title
(
p
i
;
p
j
)
D
T
p
i
:
T
p
j
j
T
p
i
jj
T
p
j
j
D
P
k
b
D
1
(
t
bi

t
bj
)
q
P
k
b
D
1
t
2
bi

q
P
k
b
D
1
t
2
bj
(7)
Theoverallsimilaritybetweenashortlistedpaper(
p
i
)and
theseedpaper(
p
j
)iscalculatedasaweightedsumofthetwo
similarities.
Sim
(
p
i
;
p
j
)
D
c

Sim
_
abstract
(
p
i
;
p
j
)
C
(1

c
)

Sim
_
title
(
p
i
;
p
j
)
(8)
where
c
2T
0
;
1
U
isatuningparameter.
Sim
(
p
i
;
p
j
)isusedto
findsimilaritywiththeseedpaper(SeeAlgorithm
1
).Top
R
papersaccordingtotheabovesimilarityarealsochosenwiththe
topmostpaperbeingpaperofinterest(
I
)foragivenseedpaper
asdiscussedinSection
8.1.4
.
Generally,researchersciteconceptuallyrelatedandrelevant
paperstotheirwork.Butallcitedpapersarenotconceptually
relatedtothecitingpaper,andtheircorrespondingvenuesmay
notbesimilartothevenueofseedpaper.
Tocaptureboththestrengthofconnectionaswellasse-
manticssuchastherelatedtopicssharedbypapers,weapply
ahybridapproachoflinkanalysisandtopic-orientedintra-graph
clusteringinabibliographiccitationnetwork.
Toreducethetimecomplexity,weperformintra-graphclus-
teringintwostages:
(i)
Tofindsub-graphsfortheentirecitationnetworkfound
aftercentralitymeasurebasedonmodularity
13
maximiza-
tion.
(ii)
Withinasub-graphapplyintra-graphclusteringbasedon
bothlinkandcontentinformation.
Thereareotherreasonsforthistwo-stageintra-graphcluster-
ing.Weattempttoclustertheentirecitationnetworkfoundafter
centralitymeasuresusingtheJarvis-Patrickalgorithm.Butdue
tounexpectedbehaviorofcitationrelationshipandnon-globular
natureofpapers,thefinalclustersarefoundtohavealessintra-
clustersimilarity.Duetoirregulardimensionalityorsparseness
relationshipamongpapers,theclustersfoundareeithervery
largeorclusterswithlessnumberofpapersorsometimesresults
withsingletonclusters.
Weencounteredacoupleofissue,
14
Ifwetrytoclusterthe
entirecitationnetworkwithoutapplyingintermediatenetwork
partitioning.Togetdenseclusters,clusterswithvaryingshapes,
13
Modularityofapartitionisascalarincentivebetween

1and1that
estimatesthedensityofconnectionsinsidesub-graphswhencontrastedwith
joinsbetweensub-graphs.
14
WhenJarvis-Patrickalgorithmwasemployedon32,0,69papersshortlisted
aftercentralitymeasures;fewclusterswerewiththeaveragenumberofpapers
morethan700,somewithlessthan3papersorevenasinglepaper.
/>Page 9
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
9
sizes,anddensities(eithernotexactlylargerinsizenorsingleton
clusters),andtohandlehighdimensionalitywe,therefore,apply
networkpartitioningbeforeapplyinggraphclustering.
Algorithm1:
ModifiedJarvis-Patrickclustering
Input
:
Observedcitationsub-graphsSwithpaper-paperconnectivity
Output
:
Thealgorithmpartitioninputpapersintonon-hierarchicalclusters
Initialization:
Let
P=
f
p
1
;
p
2
;:::;
p
n
g
bethesetofcandidatepaperspresentinsub-graphsS
T=User-definedthresholdforsimilarity
F=minimumrequirednumberofneighborsincommon
for
i
 
1
to
j
P
j
do
for
j
 
1
to
j
P
j
do
if
(p
i
6D
p
j
)
then
for
k
 
1
to
11
do
c
 
(k-1)*0.1/*paramvaluesc={0,0.1,...,1}*/
sim
k
(
p
i
;
p
j
)
 
c

S
1
C
(1

c
)

S
2
dist
(
p
i
;
p
j
)
where,
S
1
 
abstract
_
similarity
(
p
i
;
p
j
)usingEq.
(
6
)
S
2
 
title
_
similarity
(
p
i
;
p
j
)usingEq.
(
7
)
dist
(
p
i
;
p
j
)
 
theminimumhoplengthbetween
p
i
and
p
j
end
end
end
end
for
i
 
1
to
j
P
j
do
resultant-set(
p
i
)=setofneighborsof
p
i
={
p
j
V
sim
k
(
p
i
;
p
j
)
>
D
T
foranyk}
end
for
i
 
1
to
j
P
j
do
for
j
 
1
to
j
P
j
do
if
j
resultant-set(p
i
)
\
resultant-set(p
j
)
j
>
D
F
then
cluster(
p
i
and
p
j
)
end
end
end
return
identifiedclustersalongwiththeirnon-overlappingpapers
8.1.2.Citationnetworkpartitioning
WeusetheLouvainalgorithmforgraphpartitioning[
64
].The
qualityofthepartitionsisensuredbyhighmodularityscores[
65
,
66
].Thismethodischosenoverothercommunitydetectionap-
proachesduetoitssimplicity,lessercomputationaltime,and
betterqualityofcommunities(Modularity).
Aweightedcitationgraph
G
D
(
V
;
E
),where
i
;
j
2
V
,an
edge
l
(
i
;
j
)
2
E
hasweight
w
i
;
j
.Theobjectiveofthisstepisto
partitionacitationnetwork
G
intoaset
S
ofmutuallyexclusive
andexhaustivesub-graphs
S
i
D
(
V
i
;
E
i
).
[
V
i
D
V
I8
S
i
2
S
(9)
V
i
\
i
6D
j
V
j
D

I8
S
i
;
S
j
2
S
(10)
Thestepprovidesus293numberofpartitionswhicharealmost
uniformcontainingaboutanequalnumberofpapers.
8.1.3.Topic-orientedintra-graphclustering
Weconsidereachpartitionforfurtherclusteringbasedonlink
andcontextualsimilarity.Aweightedsub-graph
S
i
D
(
V
i
;
E
i
)is
dividedhereinto
n
i
clustersusingJarvis-Patrickalgorithm[
67
].
ThereasonbehindtheselectionofJarvis-Patricktoclustereach
sub-graphsfoundafterLouvainalgorithmare:Itwillfindtight
clustersembeddedinlooseone.Itismainlygoodfordetecting
chain-likeornon-globularclusters.Theclusteringstepsarevery
fast,andtheoverheadrequirementisverylow.Thecapability
tofindclustersofdifferentshapes,sizes,anddensitiesinhigh
dimensionaldata.
Theobjectiveofthisstepistomakefromeachpartition
coherentclustersofpapersthatarecloselyrelatedtoeachother.
Let
C
i
beasetof
n
i
numberofsuchclustersforpartition
S
i
.
[
j
2f
1
;
2
;:::;
n
i
g
c
ij
D
C
i
(11)
c
ij
\
j
6D
k
c
ik
D

(12)
AlthoughJarvis-Patrickworkswellingraphclusteringitsuf-
fersfromaproblem.
15
Itutilizestwoparameters:theminimum
numberofcommonneighbors(
F
)andthesizeoftheneigh-
borlist(
T
)betweenapairofnodes.Buttheseparametersare
predefinedbeforeapplyingJarvis-Patrickandarenotgenerally
modifieddynamically.Duetothesehand-codedorfixedsizeof
theneighborlist(
T
)incitationnetworks,wearenotguaranteed
togetclusterswithconsistentquality.Thereasonisthenon-
globularorirregulardimensionalityamongpapersinacitation
network.
Toaddresstheaboveissueandtocatchagatheringofmore
similarobjectsinonecluster,wealtertheoriginalJarvis-Patrick
algorithm.Avariable-lengthnearestneighborlist,aproximity
thresholdisutilizedtodecideavariablenumberofneighbors
foreachpaper.Allneighborsthatpassthesimilaritythreshold
areconsideredasneighborstothispaper.Bythisalteration,
outliersarepreventedfromjoiningaclusterwhilepreventing
thearbitrarysplittingoflargeclustersisemergingfromthe
limitationsimposedbythefixed-lengththreshold.Thedetailed
stepsaregiveninAlgorithm
1
.Thisstepprovidesus387number
ofclusters.
Algorithm2:
Sub-clustersmergingalgorithm
Input
:
Identifiedsub-clustersalongwithnon-overlappingsetofpapers
Output
:
Mergingclusterstocollectrelevantcandidatesetofpapers
Initialization:
Let
C
=
S
i
f
c
i
1
;
c
i
2
;:::;
c
in
i
g
bethesetofsub-clustersforallthepartitionstaken
together(foundafterapplyingJarvis-Patrickalgorithm)
R
=
f
r
1
;
r
2
;:::;
r
r
g
bethesetoftopmost
r
similarpapersbyusingEq.
(
8
)
candidate
_
set
D

for
i
 
1
to
j
R
j
do
for
j
 
1
to
j
C
j
do
if
(r
i
2
c
ij
)
then
candidate
_
set
D
candidate
_
set
S
c
ij
/*Allpapersin
c
ij
*/
end
j
 
j
C
1
end
i
 
i
C
1
end
collectthesetofidentifiedsub-clustersandmergethem
return
finalcandidate_set
8.1.4.AbstractsimilarityusingOkapiBM25+algorithm
Keepinginmindtheoverallgoaltoretrieveonlyconceptually
relatedpaperswiththeseedpaper,mergingofclustersneedto
bedonebeforeapplyingabstractsimilarity.Thecompletesteps
arequotedinAlgorithm
2
.Toperformsuchmerging,weneedto
takeaftertheaccompanyingrulesasgivenbelow:
(i)
SelecttopRpapersconsideringthecumulativescoreof
abstractandtitlesimilaritywithseedpaperasdiscussed
andexaminedinSection
7
andSection
8.1.1
.
(ii)
Selectthetopmostsimilarpaperaspapertheofinterest
(
I
)andextractitsassociatedvenueasthevenueofinterest
(
Z
).
(iii)
Takeindividuallyselectedpapers(R)andidentifytheircor-
respondingclustersfoundbytheJarvis-Patrickalgorithm.
15
BetweenanytwopapersAandB;Amayhaveahighnumberofneighbors
whileBhavingveryfewduetothefixedsizeofneighborlists.Nowforthe
minimumnumberofcommonneighbor(
F
)andsizeoftheneighborlist(
T
),A
andBcannotcometoaclusteralthoughtheyaresemanticallyquitecloseand
relatedpapersinabibliographiccitationnetwork.
/>Page 10
----------------------------------------------------------------------------------------------------<10
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
Table4
Researchtopicdistributionofvenue
v
i
.
Year
Topic
1
Topic
2
Topic
3
Topic
4
Topic
5
20080.40.30.200.1
200900.30.20.40.1
20100.100.60.20.1
20110.50.20.200.1
20120.30.300.20.2
Table5
Weightedscoreoftopicdistributionofvenue
v
i
.
Year
Topic
1
Topic
2
Topic
3
Topic
4
Topic
5
20080.150.110.0700.03
200900.120.080.170.04
20100.0500.30.10.05
20110.310.120.1200.06
20120.30.300.20.2
(iv)
Extractallpaperspresentinthoseidentifiedclusters(as-
sume
t
1
)andmergethemwiththeselectedtoppapers
fromset-II(assume
t
2
).
SoaftergettingtopRsimilarpaper,mergingofclustersis
donebyusingAlgorithm
2
.Inourexperiment,wehavegenerally
considered(
t
1
C
t
2
)paperstochecktheabstractsimilarity
withtheseedpaper.Ithasbeenexperimentallyobservedthat
therearepapers(
t
1
)presentafterthemergingofclusters.
ToaddressthedeficiencyofOkapiBM25initstermfrequency
(TF)normalizationcomponent,i.e.,theTFnormalizationisnot
lowerboundedproperly,inthispaper,weadaptedOkapiBM25
C
(avariantofOkapiBM25)tocomputetheabstractsimilarity
of
P
seed
,and
P
test
papers.Itisspecificallyappliedtoretrieve
onlyconceptuallyrelatedpaperswithseedpaper.OkapiBM25
C
isbasedontheprobabilisticretrievalframework[
68
],whose
weightingbasedsimilarityscorecanbeexpressedasfollows.
Abstractsimilarity(
P
seed
;
P
test
)
D
X
t
2
P
seed
\
P
test
ln

P

w
f
C
0
:
5
w
f
C
0
:
5

:
 
(
n
1
C
1)
:
cf
n
1
(1

r
C
r
w
l
a
vw
l
)
C
cf
C

!
:
(
n
3
C
1)
:
qcf
n
3
C
qcf
(13)
where,
cf
istheterm
t
sfrequencyintestingpaper(
P
test
),
qcf
is
thetermsfrequencyinseedpaper(
P
seed
),
P
isthetotalnumber
ofpapersidentified(
t
1
C
t
2
),
w
f
isthenumberoftestingpapers
thatholdtheterm
t
,
w
l
isthelengthofabstract(inbytes),
a
vw
l
istheaverageabstractlengthofpapersineachcomponents,
n
1
(between
r
(usually0.75),
n
3
(betweenandthe
valueof

isaconstant(usually1.0).
Thepapersaresortedandrankedindecreasingorderoftheir
similarityscorewiththeseedpaper.Therankedpapersareused
tofetchthevenuesinthesameorderandsuggestuser-specified
top
N
(usually
N
6D
t
1
or
t
2
)uniquevenues.
8.2.ThearchitectureofVVPNmodel
Weareattemptingtodiscoverinherentcommunitystructures
inaAuthor-AuthorGraph(AAG)tounderstandthenetworkmore
profoundlyandrevealinterestingrelationshipssharedamong
venues.Tomeasurethetopicdistributionofvenuestocapture
theirrespectivecurrentscope,age-discountedbasedVenue2Vec
isproposed.
TheprocessofVVPNmodelmainlyinvolvessixsteps:(i)
Venuesscopevariationwithtime,(ii)Venue2Vecedgeweighting,
(iii)Generationofthevenue-venuegraph(VVG),(iv)Combining
meta-pathfeatures,(v)Computingmeta-pathedgeweightsas
features,and(vi)RecommendationofbiasedRWRmodel.
8.2.1.Venuesscopevariationwithtime
Researchersusuallydesiretocontactthosevenueswhichare
currentlypublishingsimilarresearchpapers.Hence,topicdis-
tributionandtitleembeddingsinrecentyearscandescribethe
currentscopeofavenuemoreaccurately.
Table
4
displaysthe
topicdistributionofvenue
v
i
.Toquantifyavenuesscope,weini-
tiallycategorizetheirpublicationsyear-wisetocapturethetopic
distributionofvenueusingtheirpublishedpapersasdepictedin
Table
4
.
Tocapturethevariationofthescopeofvenues,weapply
LDAbasedtopicmodelingonabstractandDoc2Veconthetitle
ofpaperspublishedinvenues.LDAgivestheyearwisetopic
distributionofthevenuesandDoc2Vecreturnsavectorforeach
yearbasedoncontextualinformationfromvenuespublished
titles.TheresultsfromLDAandDoc2Veccanbeconsideredas
twosetsofvectors.
L
v
i
representsthevectorofyear-wisetopic
distributionvectorsand
D
v
i
representsthevectorofyear-wise
titleembeddingsvectorsasdepictedinEq.
(
14
)
andinEq.
(
15
)
respectively.Theyearsconsideredare2000,2001,...,2012.Each
year-wisevectorisagainavectorof
k
differenttopicsasgivenin
Eqs.
(
19
)
and
(
20
)
.
L
v
i
DT
L
v
2000
i
;
L
v
2001
i
;:::;
L
v
2012
i
U
(14)
D
v
i
DT
D
v
2000
i
;
D
v
2001
i
;:::;
D
v
2012
i
U
(15)
Now,weemployaweightedadditionofvectorsfromeachset
togetonevectorforabstractsimilarityandonevectorfortitle
similarity.Weuseage-discountedscheme(inverselog-weighting
scheme)togivemoreweighttothecurrentyearvectors,andthe
weightreducesinthedecreasingorderofyears.Foreachvenue
v
i
,wegetavector
A
v
i
forabstractsimilarityandvector
T
v
i
fortitle
similarityasdepictedinEq.
(
16
)
andinEq.
(
17
)
respectively.
A
v
i
D
X
y
i
2
Y
L
v
y
i
log
2
(
y
o

y
i
C
2)
;
and
(16)
T
v
i
D
X
y
i
2
Y
D
v
y
i
log
2
(
y
o

y
i
C
2)
where
(17)
Y
Df
2000
;:::;
2012
g
and
y
o
isthelatestyearin
Y
:
(18)
L
v
y
i
DT
a
1
i
;
a
2
i
;:::;
a
ki
U
(19)
D
v
y
i
DT
a
1
i
;
a
2
i
;:::;
a
ki
U
(20)
Using
A
v
i
and
T
v
i
foravenue
v
i
,wecomputecosinesimilaritywith
theircounterpartfromtheseedpaperasdiscussedinnextsection
Venue2Vecedgeweighting.
Example.
Table
4
showstheinitialtopicdistributionsforfive
topicsofvenue
v
i
and
Table
5
showsthetopicdistributionafter
age-discountedweightingschemebeingapplied.Eq.
(
21
)
shows
thetopicdistributionvectorofvenue
v
i
inyear2010.Theage-
discountedvectorisgivenbyEq.
(
22
)
(latestyear
D
2012).
A
v
2010
DT
0
:
1
;
0
;
0
:
6
;
0
:
2
;
0
:
1
U
(21)
A
v
2010
log
2
(4)
DT
0
:
05
;
0
;
0
:
3
;
0
:
1
;
0
:
05
U
(22)
Furthermore,weadoptaweightedadditionofvectorstoobtain
thefinalvector,asgivenin
Table
5
.Thefinalvector
A
i
forvenue
v
i
afterweightedadditionwillbe:
A
v
i
DT
0
:
81
;
0
:
65
;
0
:
57
;
0
:
47
;
0
:
38
U
(23)
/>Page 11
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
11
Table6
Meta-pathsusedinVVPNmodel.
No.Meta-pathDescription
1.
common
_
author
Corevenuesshareanauthor
2.
common
_
term
Corevenuesshareaterm
3.
direct
_
cites
Corevenuecitescorevenue
4.
direct
_
cited
_
by
Corevenuescitedbycorevenues
5.
citation
_
paper
Corevenuesshareareference(ref)
6.
co
_
citation
_
paper
Corevenuesco-citedtogether(cite)
Ifwehadappliedasimplevectoradditionwithoutanyweights,
wewouldhavegotavector
A
v
i
0
as:
A
v
i
0
DT
1
:
3
;
1
:
1
;
1
:
2
;
0
:
8
;
0
:
6
U
(24)
Wecanclearlyseethedifferencebetween
A
v
i
and
A
v
i
0
.Itclearly
indicatestheinfluenceoftopicdistributionvectorofrecentyear
2012inthecalculationof
A
v
i
whereasin
A
v
i
0
,alltheyearwise
vectorscontributeequally.Furthermore,venue-venuesimilarity
isdoneamongvenuesexploitingtheircorrespondingweighted
vector
A
v
i
and
T
v
i
respectively.
8.2.2.Venue2Vecedgeweighting
Using
A
i
and
T
i
foravenue
v
i
,wecomputecosinesimilaritybe-
tweenanytwovenues.Wegettwocosinesimilarities,
Sim
a
(
v
i
;v
j
)
and
Sim
t
(
v
i
;v
j
),forapairofvenues,
v
i
and
v
j
,using(
A
i
;
A
j
)and
(
T
i
;
T
j
)respectively.
Sim
a
(
v
i
;v
j
)
D
A
v
i
:
A
v
j
j
A
v
i
jj
A
v
j
j
D
P
k
b
D
1
(
a
b
;
i

a
b
;
j
)
q
P
k
b
D
1
a
2
b
;
i

q
P
k
b
D
1
a
2
b
;
j
(25)
Sim
t
(
v
i
;v
j
)
D
T
v
i
:
T
v
j
j
T
v
i
jj
T
v
j
j
D
P
k
b
D
1
(
t
b
;
i

t
b
;
j
)
q
P
k
b
D
1
t
2
b
;
i

q
P
k
b
D
1
t
2
b
;
j
(26)
Nowweutilizethesetwosimilaritymetricstogetonefinal
metric,
Sim
(
v
i
;v
j
)withthehelpofanadjustmentparameter
m
as:
Sim
(
v
i
;v
j
)
D
m

Sim
a
(
v
i
;v
j
)
C
(1

m
)

Sim
t
(
v
i
;v
j
)
(27)
where
m
2T
0
;
1
U
.
Weconsiderthissimilarityscoreascontextualsimilarityfea-
tures(CSF).WeareusingthisCSFscoreinSection
8.2.3
togen-
erateaweightedVVG(venue-venue)graphandalsotocompute
theedge-weightamongvenues.
8.2.3.Generationofvenue-venuegraph(VVG)
Inthissection,wewillcreateahomogeneousundirected
venue-venuegraph(VVG)fromtheHINgraphtorecommend
relevantvenuestotheinputseedpaper.Wedefinethisgraphas
anundirectedgraph,VVG
D
(B,D)withavertextypemapping
function
!
:B
!
B
andanedgetypemappingfunction

V
D
!
D
.Here,wehaveonetypeofvertexBforeachvenue.
B
Df
setofvenueswhereonly
P
_
main
paperspublished
g
(28)
ThetypeofedgeDisdefinedas
b
1
connects
!
b
2
V
!
(
b
1
)
2
f
P
_
main
g
;!
(
b
2
)
2
f
P
_
main
g
;
b
1
;
b
2
2
B
.
Itjoinstwovenuesusingonlyonetypeofedgesuchthat
b
1
d
1
!
b
2
,where

(
d
1
)
2
D
.
Table
6
listsalltypesofmeta-paths
definedinourmodel.Weareextractingthevenueof
P
_
main
andconsideringasacorevenuetomaintainahomogeneousVVG
graph.Initially,theCSFscoreascomputedinSection
8.2.2
among
venuesisusedtocreatetheVVGgraph.TheaverageCSFscoreis
usedasathresholdtocreatetheedgebetweenvenues.Noedge
existswithlessthanaverageCSFscorefoundamongvenues.
8.2.4.Combiningmeta-pathfeaturesintoVVG
Sincemeta-pathsaremostlycompositerelationsofvarious
edgetypesinaHINgraph,theycancapturethedistinctrela-
tionshipbetweenapairofHINvertices[
55
].Weassumethata
meta-pathconnectstwodifferent
P
_
main
papers
x
;
y
thatbelong
totwodisjointcorevenues
v
i
,and
v
j
respectively.
Weobservedthatmeta-pathfeatureswithmorethantwode-
gree
16
arenotmuchmeaningfulinourworkandevennotableto
createmuchdifferencetocomputethesimilarityamongvenues.
Toreducethetimecomplexityandtoobtainatightlycoupledre-
lationshipamongvenues,onlyone-degreeandtwo-degreemeta-
pathfeaturesareincorporatedintothisVVPNmodel,andahomo-
geneousVVGgraphisexploitedtorecommendacademicvenues.
Webelievethatresearchpapersthatsharemanysimilarrefer-
encesmayuseacommonsetofbackgroundknowledge.Byusing
thishypothesis,thisinformationcouldbeusedtocomputethe
possibleassociationsamongpapers.
8.2.5.Computingmeta-pathedgeweightsasfeatures
Todiscoverthelatentassociationbetweenvenues,wehave
dividedtheabovesixmeta-pathsasdepictedin
Table
6
into3
categoriesofedgeweighting.
(i)
Common
_
Features
(CF):Commonauthorandcommonterm
meta-pathbelongtothiscategory.Commonauthorsimi-
larityandcommontermsimilaritybetweentwovenues
v
i
and
v
j
arerepresentedby
Sim
A
(
v
i
;v
j
)and
Sim
T
(
v
i
;v
j
)re-
spectively.Termappearingintitlesorabstractsofa
P
_
main
paperafterstopwordremovalandstemmingareconsider
forsimilaritycomputation.Weusesnowballstemmerto
gettherootwords[
69
].Jaccardsimilaritycoefficientis
usedtocalculateboth
Sim
A
(
v
i
;v
j
)and
Sim
T
(
v
i
;v
j
)Eq.
(
29
)
.
Incaseofcomputationof
Sim
A
(
v
i
;v
j
),sets
E
and
F
denote
listofauthorsassociatedwithvenue
v
i
and
v
j
respectively.
J
(
E
;
F
)
D
j
E
\
F
j
j
E
[
F
j
(29)
where0

J
(
E
;
F
)

1.
Similarlyduring
Sim
T
(
v
i
;v
j
)computation,sets
E
and
F
denotesampletermsoccurinvenue
v
i
and
v
j
respec-
tively[
70
].Thenwearecombiningtheabovetwosimilarity
scorestoobtainCFscore(Common_Features)betweentwo
venues
v
i
and
v
j
respectively.ThecomputationofCFedge
weightingbetween
v
i
and
v
j
isdefinedbelow.
CF
(
v
i
;v
j
)
D
Sim
A
(
v
i
;v
j
)
C
Sim
T
(
v
i
;v
j
)
(30)
Generally,noneoftheCFsimilarityscoresamongtwo
venueswillgetaperfectscoreof1,andalsorandomwalk
issensitivetoahigherprobabilityscore.Normalizationof
datawithinauniformrange(e.g.,isessentialto
preventlargerappliestotheoutputvariables.Thisrepre-
sentationnumbersfromoverridingsmallerones.Oneway
istoscaleinputandoutputvariables(z)intheinterval
[

1
;
1
]correspondingtotherangeofthetransferfunc-
tion[
71
].Beforeaddingthismeta-pathCFscoreintothe
model,weareindividuallyapplyingthenormalizationto
beintherangeofasshowninEq.
(
31
)
.
z
i
D

1
C
(

2


1
)
(
x
i

x
min
i
)
(
x
max
i

x
min
i
)
(31)
Afterapplyingthisnormalization,wewillgetanormalized
CFscore
CF
0
(
v
i
;v
j
)amongtwovenues
v
i
and
v
j
.
16
Thedegreeofameta-pathindicatesitslengthandthedistancebetween
twomainpapers.
/>Page 12
----------------------------------------------------------------------------------------------------<12
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
(ii)
Direct

Citation
_
Features
(DCF):Themeta-pathssuchas
direct_citesanddirect-cited-byareincludedinthisgroup.
ThecomputationofedgeweightingofDCFisdefinedbe-
low.
DCF
(
v
i
;v
j
)
Dj
P
ij
jCj
P
ji
j
(32)
Where
P
ij
denotessetofpaperspublishedatvenue
v
i
and
referringtopaperspublishedatvenue
v
j
.Afterapplyingthe
normalizationdefinedinEq.
(
31
)
,wewillgetanormalized
DCFscore
DCF
0
(
v
i
;v
j
)amongtwovenues
v
i
and
v
j
.
(iii)
Co

Citation
_
Features
(CCF):Theremainingmeta-paths
suchascitation_paperandco-citation_paperarewithin
thisgroup.ThecomputationofedgeweightingofDCFis
definedbelow.
CCF
(
v
i
;v
j
)
D
X
k
6D
i
;
k
6D
j
j
P
ik
\
P
jk
jC
X
k
6D
i
;
k
6D
j
j
P
ki
\
P
kj
j
(33)
where
P
ik
isthesetofpaperspublishedatvenue
v
i
andre-
ferringtopaperspublishedatvenue
v
k
.Afterapplyingthe
normalizationdefinedinEq.
(
31
)
,wewillgetanormalized
CCFscore
CCF
0
(
v
i
;v
j
)amongtwovenues
v
i
and
v
j
.
Weaddeachnormalizedmeta-pathscoresintothemodelto
analyzetheireffectontherecommendationquality.Wealready
haveinitialedgeweightingscoreCSF,whichiscomputedbased
ontheage-discountedscheme(inverselogweightingscheme)
basedabstractandtitlesimilarityascalculatedinSection
8.2.2
.It
waspurelybasedonthecontextualsimilaritytobeintherange
ofSoafterapplyingnormalizationdefinedinEq.
(
31
)
,we
willgetanormalizedCFscore
CSF
0
(
v
i
;v
j
)amongtwovenues
v
i
and
v
j
.
CSF
0
(
v
i
;v
j
)
D
Sim
(
v
i
;v
j
)
(34)
Initially,therecommendationwillbeprovidedbasedonthe
normalized
CSF
0
matchingscore.
CWS
(
v
i
;v
j
)
D
CSF
0
(
v
i
;v
j
)
(35)
Weneedtocombineindividualnormalizedmeta-pathscores
intothemodel,andwecallitacombinedweightedscore(CWS).
InadditiontonormalizedCSFscoreallnormalizedscoresob-
tainedfrom
Eqs.
(
30
)
,
(
32
)
and
(
33
)
areaddedtoobtainthe
CWS(
v
i
;v
j
)toincreasetheprobabilityofrecommendingrelevant
venuesduringrecommendation.TheCWSscorecanbeusedas
aprobabilityscorebetweenvenuesinVVGgraphascomputed
usingEq.
(
38
)
toapplyrandomwalkwithrestart(RWR).
CWS
(
v
i
;v
j
)
D
CSF
0
(
v
i
;v
j
)
C
CF
0
(
v
i
;v
j
)
C
DCF
0
(
v
i
;v
j
)
C
CCF
0
(
v
i
;v
j
)
(36)
9.Fusionmodel:CNAVER(Layer-4)
Tobemorespecific,thepredictionsresultingfromthePPPN
modelandVVPNmodelarefirstproducedseparately,allowing
ustoleveragetheindividualstrengthsofbothapproachessince
thereisnointerdependencybetweenthem.
9.1.Topvenuesrecommendation(PPPNmodel)
WeapplyLDAonabstractandDoc2VeconthetitleforSet-
IIpapers(Section
6
)andthetop
t
2
similarpapersarechosen.
AbstractandtitlesimilarityiscomputedasdiscussedinSec-
tion
8.1.1
.Wehavefourassumptionsregardingtheinclusionof
these
t
2
papersobtainedfromSet-IIpaperforabstractsimilarity.
(a)
Theremaybefewpaperswhicharerecentlygotpublished
withouthavinganycitations(Set-II),maybeinvolvedwith
manyreputedvenues.
(b)
Theseedpaperstitleandkeywordsarematchingwith
somepapersinSet-IIsothereisapossibilitythattheseed
papermaygetacceptedatsimilarvenuesasthatofSet-II
papers.
(c)
Generallythepaperspublishedinreputedvenuesgeta
highnumberofcitations.Chancesofgettingacceptancein
anewvenuearerelativelyeasierthanreputedvenues.
(d)
Newvenuesshouldgetanequalchanceofinclusionin
thefinalrecommendationtoreasonableaddressthenew
venuecold-startissue.
9.2.Topvenuesrecommendation(VVPNmodel)
Toexploitcollaborationnetworkinformationalongwithpub-
licationcontent,weemployapopularnetwork-basedapproach
knownasarandomwalkwithrestart(RWR).RWRprovidesan
excellentwaytomeasurehowcloselyrelatedtwonodesarein
agraph[
72
].ThecoreequationoftheRWRmodelisshownin
Eq.
(
37
)
.
R
(
t
C
1)
D

S
R
(
t
)
C
(1


)
Q
(37)
where
S
isthetransfermatrix,representingtheprobabilityfor
eachnodetojumptoothernodes.
R
(
t
)
istherankscorevector
atstep
t
and
Q
istheinitialvectoroftheform(0
;:::;
1
;:::;
0).
Initially,therankscoreofthetargetnodeis1,whileothersare
0.

isthedampingcoefficient.Withprobability(1


),walker
restartsfromthestartnode.Weusethetransfermatrix
S
tobias
ourwalkersbehavior.
Weusetheweightedcombinedscore(CWS)foundafterag-
gregatingvariousmeta-pathsfeaturesinEq.
(
36
)
,tobiasthe
walkertowardsnodeswithahighercontentaswellassemantical
similarity.Edgeweight
w
v
i
;v
j
foranedgefrom
v
i
to
v
j
isgivenby
theequationbelow:
w
v
i
;v
j
D
CWS
(
v
i
;v
j
)
P
x
2
N
(
v
i
)
CWS
(
v
i
;
x
)
(38)
where
N
(
v
i
)issetofnodeswhichhaveincominglinksfrom
v
i
.
RWRisaniterativeprocess.Aftercertainiterations,
R
(
t
)
converges
toasteady-stateprobabilityvector.Weuse
R
(
t
C
1)
venue-rank
scorevectortogiveourfinaltopNrecommendation.
Algorithm3:
FusionofPPPNandVVPNmodels
Input
:
shortlistedpapersafterOkapiBM25
C
(
t
1
)andshortlistedSet-IIpapers(
t
2
),
Venueofinterest(
Z
)foragivenseedpaper
p
m
Output
:
TopNrecommendedlistofvenuesfor
p
m
Initialization:
Let
T=
t
1
C
t
2
bethesetofcandidatepapers
L
=Orderedlistofuniquevenuesfromtop-rankedpapersbasedonabstract
similarityscores(Section
8.1.4
)
=
f
a
1
;
a
2
;:::;
a
N
g
BordaCount
B
c
(
a
i
)
 
N

i
C
1
M
=Orderedlistofuniquevenuesindecreasingorder(Section
9.2
)
=
f
b
1
;
b
2
;:::;
b
N
g
BordaCount
B
c
(
b
i
)
 
N

i
C
1
N
=Finallistofuniquevenues
=
f
v
1
;v
2
;:::;v
j
N
j
g
where
j
N

2
N
for
i
 
0
to
j
L
j
-1
do
for
j
 
0
to
j
M
j
-1
do
if
(a
i
DD
b
j
)
then
BordaCount
B
c
(
v
i
)
 
B
c
(
a
i
)
C
B
c
(
b
j
)/*theyaresamevenue*/
else
individuallyconsiderBordaCount
B
c
(
v
i
)
 
B
c
(
a
i
)and
B
c
(
v
j
)
 
B
c
(
b
j
)
end
end
end
SortvenuesinthedecreasingorderofBordaCount(
B
c
(
v
i
))
PreparethefinallistoftopNvenuesrecommendation
/>Page 13
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
13
9.3.Finalvenuesrecommendation(Fusionmodel)
Althoughthesocialnetworkanalysis(SNA),content-based
filtering(CBF)andrandomwalkwithrestart(RWR)arewidely
usedformakingvenuerecommendations,theymaynotprovide
thebestrecommendationresultsduetotheirlimitations.After
gettingtheindividualtopNrecommendationsfromboththe
PPPNmodelandVVPNmodel,weneedtoapplysomerank-based
fusionbecausethefusioncanprovidebetterrecommendation
thanasingleapproachandthedisadvantagesofoneapproach
canbeovercomebytheother.
Fusionhasbeenwidelyinvestigatedintherecommendation
community.Theywereoftendividedintotwocategories:score-
basedandranking-based.Score-basedcombinationmethodsre-
quiresimilarityinformationtoconductrankinglistaggregation,
suchasCombSum,CombMNZ,andweightcombination[
73
,
74
].
Ranking-basedcombinationmethodsneedrankorpositionin-
formationtointegratedifferentcandidatesrankinglists,such
asBordafusion,Condorcetfusion,andMAPFuse[
75
].Inthis
research,theBordafusiontechniqueisappliedtoincorporatethe
existingpredictionlistsgeneratedbythePPPNmodel,andthe
VVPNmodelasPPPNprovidesscoresforeachvenuewhileVVPN
providesranksofthem[
76
].Thecompletestepsarequotedin
Algorithm
3
.
10.Experiments
Inthissection,wepresenttheexperimentsoftheproposed
fusionmodel``CNAVERtoevaluatetheeffectivenessofit.In
thissection,wepresenttheexperimentaldatasets,evaluation
strategy,evaluationmetrics,experimentalsetting,parametertun-
ing,andbaselinemethods.Allexperimentsareperformedon
alaptopwith64bitWindows10operatingsystem,Inteli7-
3540M,CPU@3.00GHz,and8GBmemory.Alltheprogramsare
implementedinpython.
10.1.Datasetused
Weuseareal-worlddatasetDBLP-citation-networkV10,
17
thecitationdataextractedfromDBLP,ACM,MAG(Microsoft
academicgraph),andothersources[
77
]todemonstratetheef-
fectivenessofourproposedmethod.Thetenthversioncontains
3,079,007papersand25,166,994citations.Eachpaperisassoci-
atedwithabstract,authors,title,publishingyear,venue,andref-
erenceslist.Afterremovingduplicatepapers,paperswithmissing
fields,andinconsistententriesinthedatabase,weareleftwith
2,236,968papers.
Weperformedourexperimentsonasubsetofthedataset
(datacollectedinbetweentheyearfrom
Tangetal.[
77
].Duetohardwareconstraints,onlyasubsetof
theoriginaldatasetisusedfortheexperimentation.Sincepapers
comingfromvariousfieldsnotonlyhavevariedresearchinterests
butalsomayhaveinterdisciplinarycollaborationsresultingin
adiversenumberofpublishedvenues.Moreover,itiscommon
topracticewithsamplingwithmanystudies.Inthispaper,
we,dividedthedatasetintotwopartsaccordingtotheyearof
publication:dataduringtheyearsasthetrainingset,
andtherestasatestingset.
10.2.Evaluationstrategy
Weadoptthefollowingtwokindsofevaluationtomeasure
theperformancesofCNAVERagainstotherstate-of-the-artmeth-
ods.
(a)
Coarse-levelorofflineevaluation
:Asthenamesuggests,it
providessomeraw-levelquicknotionofhowtheproposed
17
https://aminer.org/citation
CNAVERfaresvis-a-visothersystems.Wefocusonthe
predictionaccuracytoseewhethertheoriginalpublication
venueforthetestpaperispredictedornot,andifyes,at
whatrankwithinsometopNrecommendations.Accuracy,
MRR,and
F

measure
macro
evaluationmetricsareuseddur-
ingtheevaluation(detailedbelow).Wecallthisscenario
offline
becausewecanevaluateasystemthiswayonly
whenwehaveannotatedtestdata.
(b)
Fine-leveloronlineevaluation
:Thisevaluation-scenariois
morerealistic(and,thatiswhywecall
online
)asare-
searcherneedstohavemorethanonevenuerecommenda-
tionfromasystemforherpaper-in-writingthatshewants
tocommunicate.Herewegoalittledeeperandaimtosee
therelevance,usefulness,andqualityoftherecommended
results.Thesystemrecommendsanorderedlistofvenues
thatareassessedbyexpertsintermsofgradedrelevance
Eq.
(
52
)
.Precision,nDCG,andaveragevenuequalityare
usedasevaluationmetricsintheevaluation.
10.3.Evaluationmetrics
Weemployedeightmetricssuchasaccuracy,MRR,
F

measure
macro
,precision@k,nDCG@k,averagevenue-quality
(Ave-quality),diversity,andstabilitytoevaluatetheperformance
ofCNAVER.Detailedinformationaboutthesemetricshasbeen
discussed[
78
].
(a)
Accuracy@N:Itistheratioofno.oftimesoursystem
correctlypredictstherealpublicationvenuewithintopN
recommendationsforasetofpapers[
20
,
36
].HereNvaries
among3,6,9,12and15respectively.
Accuracy
@
N
D
#correctlypredictsvenueswithintopN
Totalnumberoftestpapers
(39)
(b)
MeanReciprocalRank(MRR):MRRisthearithmeticmean
ofreciprocalrank(RR)whichistheinverseofthefirstrank
wherethecorrectvenueisrecommendedintheranked
result[
79
].
MRR
D
1
j
Q
j
j
Q
j
X
i
D
1
1
rank
rel
i
(40)
where
rank
rel
i
denotestherankpositionofthefirstrelevant
documentforthe
i
thqueryinaquerysetQ.
(c)
F

measure
macro
(
F
1
):Themacro-averageistheaverage
ofthesamemeasurescalculatedforallclasses.Ittreats
allclassesequally.Foranindividualclass
C
i
(numberof
venues),theassessmentisdefinedby
tp
i
(truepositives),
tn
i
(truenegatives),
fp
i
(falsepositives),and
fn
i
(falseneg-
atives)[
80
,
81
].
Precision
macro
D
P
N
i
D
1
tp
i
tp
i
C
fp
i
N
(41)
Recall
macro
D
P
N
i
D
1
tp
i
tp
i
C
fn
i
N
(42)
F

measure
macro
D
2
Precision
macro

Recall
macro
Precision
macro
C
Recall
macro
(43)
(d)
Precision:Precisionisthefractionofretrieveditemsthat
arerelevant.Inourcontext,itisthefractionofrecom-
mendedvenuesthatarerelevant,asshowninEq.
(
44
)
.
Precision
D
j
relevantvenues
\
recommendedvenues
j
totalrecommendedvenues
(44)
Precision@kmeanswhen
k
venuesarerecommended,i.e.,
Precision
@
k
D
j
relevantvenues
\
recommendedvenues
j
k
(45)
/>Page 14
----------------------------------------------------------------------------------------------------<14
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
(e)
Normalizeddiscountedcumulativegain(nDCG):Itrepre-
sentstheratioofdiscountedsystemgainanddiscounted
idealgainaccumulatedataparticularrank
p
,wheregain
atarank
p
isthesumofrelevancevaluesfromrank1
torank
p
[
79
].Relevancevalueinoursystem(
rel
sj
)isa
score(0,1or2)assignedbyaresearchertothevenueat
position
j
.Idealvectorisconstructedhypotheticallywhere
allrelevancescores(
rel
ij
)areorderedindecreasingorder
toensurethehighestgainatanyrank.
DCG
sp
D
rel
s
1
C
p
X
j
D
2
rel
sj
log
2
(
j
)
(46)
IDCG
p
D
rel
i
1
C
p
X
j
D
2
rel
ij
log
2
(
j
)
(47)
nDCG
p
D
DCG
p
IDCG
p
(48)
(f)
Diversity(D):Itisdefinedastheaveragedissimilarity
(oppositeofsimilarity)betweenallpairsofitemsinaresult
set[
82
].
D
D
2

P
N
i
D
1
P
N
j
D
1
(1

Similarity
(
v
i
;v
j
))
N
(
N

1)
(49)
where
N
isthelengthoftherecommendation,
v
i
and
v
j
arethevenuesappearingintherecommendationlistsand
Similarity(
v
i
;v
j
)denotesthecontent(abstract,keywords)
similarityamongvenues
v
i
and
v
j
.
(g)
Stability:Arecommendersystemisstableifthepredictions
donotchangestronglyoverashortperiodoftime[
34
,
83
].
Itisalsocalledmeanabsoluteshift(MAS),designedto
capturetheinternalconsistencyamongpredictionsmade
byagivenrecommendationalgorithm[
3
].Itisalsodefined
throughasetoftrainingdata
R
1
andasetofprediction
(rankingoforiginalvenue)ofseedpaper,
P
1
.Foraninterval
oftime(additionofnewdataintothetrainingdata),the
recommendersystemcannowmakeprediction,
P
2
.MASis
definedas
Stability
D
MAS
D
1
j
P
2
j
X
(
u
;
i
)
2
P
2
j
P
2
(
u
;
i
)

P
1
(
u
;
i
)
j
(50)
where
P
1
,
P
2
arethepredictionsmadeinphase1andphase
2,respectively.
(h)
Average-VenueQuality(Ave-quality):Itevaluatesthequal-
ityofthevenuesrecommendedbyCNAVERbasedon
Googlesh5-index[
22
].
Average-venuequality
D
P
v
2
V
H
5
v
j
V
j
(51)
where
V
isthesetofrecommendedvenuesand
H
5
v
isthe
h5-indexofvenuev.HighertheAve-quality,wecanclaim,
thebetteristherecommendation.
10.4.Experimentalsetting
Whilepreparingthetestdataset,weconsidertwoscenar-
ios.Firstly,duetooperationalconstraints,20sub-domainsof
computersciencewereselectedasatestingdatasetinourex-
periment.Atotalof120seedpapers(6fromeachsub-domains)
arechosenmanuallyfrom20sub-domains:informationretrieval
(IR),imageprocessing(IP),security(SC),wirelesssensornetwork
(WSN),machinelearning(ML),softwareengineering(SE),com-
putervision(CV),artificialintelligence(AI),datamining(DM),
theoryofcomputation(TC),databases(DB),
interaction(HCI),algorithmsandtheory(AT),naturallanguage
processing(NLP),parallelanddistributedsystems(PDS),world
WideWeb(WWW),websemantics(WS),computerarchitecture
(CO),compilerdesign(CD)andmultimedia(MM).
Secondly,whileidentifyingseedpapersfollowingconditions
aretakenintoconsiderationtomeasuretheeffectivenessof
CNAVERtohandlecoldstartissueslikeanewvenueandnew
researcher.
(i)
Category1(2

v
c
<
8)
:Selectpaperswhoseassociated
venueshavepublicationsgreaterthanorequalto2butless
than8.
(ii)
Category2(8

v
c
<
15)
:Selectpaperswhoseassociated
venueshavepublicationsgreaterthanorequalto8butless
than15.
(iii)
Category3(15

v
c
)
:Selectpaperswhoseassociatedvenues
havepublicationsgreaterthanorequalto15.
(iv)
Category4(2

p
c
<
8)
:Selectpaperswhoseassociated
authorshavepublicationsgreaterthanorequalto2but
lessthan8.
(v)
Category5(8

p
c
<
15)
:Selectpaperswhoseassociated
authorshavepublicationsgreaterthanorequalto8but
lessthan15.
(vi)
Category6(15

p
c
)
:Selectpaperswhoseassociatedau-
thorshavepublicationsgreaterthanorequalto15.
Therearetwomajorcategories,i.e.,venuecount(
v
c
)and
publicationcount(
p
c
).Generally
v
c
denotesthenumberofpub-
lishedpapersofindividualvenueand
p
c
denotesthenumberof
publicationsofaresearcher.Itisensuredthateachcategoryis
wellrepresentedintheseedpapers.
10.4.1.Procedureofonlineevaluation
Forthisevaluation,wedidnothavethereadyannotation,but
weneedone.Theannotationorrelevanceassessmentiscollected
fromthevolunteersthroughcrowdsourcinginthebesteffort
basis.Thereare57researcherswithexpertiseinthesubjectsof
thepapersprovidedwithinputandoutputofourrecommender
systemwhereforeachpaper,15venuesrecommended.Outof57
researchers,23evaluated3paperseach,17researchersevaluated
2eachandtherest17wereevaluatedby17researchers.
Alltheexpertswereidentifiedfromacademiawithamini-
mumof3yearsofresearchexperience.MostwerehavingaPh.D.
exceptfewresearchstudentsandresearchassistantswhowere
pursuingaPh.D.withbachelorsormastersdegreeinscience
ortechnology.Theexpertsorresearchersweresochosenthat
theiractiveareasofresearchperfectlymatchwiththetopicsof
seedpapers.Among57researchers,therewere8professors,11
associateprofessors,19assistantprofessors,12seniorresearch
students,andtheremaining7wereresearchassistants.
Theexpertscheckthetitles,abstracts,authors,yearofpubli-
cation,andvenuerecommendationsofthepapersanddetermine
therelevance-leveloftherecommendations.Inthisexperiment
therelevancevalueristernary,i.e.,r
2
{0,1,2}.
Relevance(
r
)
D
(
2perfectlymatching
1partialmatching
0otherwise
(52)
Itissetto2iftheexpertagreesthattheresearchpaper
iscompletelymatchingwiththescopeofthejournal,setto1
ifthereisapartialmatchingorsetto0otherwise.Butwhile
computingprecision,wehaveassumedthepartialrelevanceas
notrelevant,i.e.,relevance1issubstitutedwitharelevancevalue
of0.
Tocomprehensivelyevaluateourproposedmethodandmore
specifically,toaddresstheresearchquestions(RQs)discussedin
Section
1
,weprefertoexaminethefollowingsub-queriesSQs:
/>Page 15
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
15
Table7
Experimentalparametersettings.
ParameterRangeDefault
Vectordimension(
k
)100
Adjustmentparameter(
c
and
m
)0.7
Similaritythreshold(T)0.35
Numberofneighbor(F)10
Topsimilarpaper(R)10
NumberofSet-IIpapers(
t
2
)15
Dampingconstant(

)0.65
Numberofrecommendednodes15
SQ1:
HoweffectiveisCNAVERincomparisontootherstate-of-
the-artmethods?
SQ2:
HowisthequalityofvenuesrecommendedbyCNAVERas
comparedtootherstate-of-the-artmethods?
SQ3:
HowdoesCNAVERhandlecold-startissuesandotherissues
likedatasparsity,diversity,andstability?
10.5.Parametertuningandoptimization
Inthissection,wedemonstratetheimpactofvariousexper-
imentalparametersettingsincludingdimensionsofvectors(k)
for
A
i
and
T
i
calculations,adjustmentparameter(
c
),threshold
(T),minimumnumberofneighbor(F),topsimilarpapers(R),
numberofSet-IIpapers(
t
2
)toperformPPPNrecommendation
andadjustmentparameter(
m
),anddampingconstant(

)to
performVVPNmodelrespectively.
Therangesanddefaultvaluesoftheparametersaredepicted
in
Table
7
.Whentheeffectoftheparameterisunderexam-
ination,theotherparametersaresettodefaultvalues.These
experimentationsareperformedinthetrainingphasecontains
knownoutput,andthemodellearnsonthisdatainordertobe
generalizedtootherdatalateron.Therangesofvaluesofvarious
parametersforwhichthemodelachieveshigherperformanceare
identifiedasoptimalparameters.Duringthisexperimentations,
thebestresultsaremarkedbythe`bold-faceineachposition.
10.5.1.Influenceofvectordimension(k)
Inordertofindtheidealdimension(k
D
no.oftopics)forLDA,
weconductexperimentsonfourvaluesforvectordimension,
i.e.,
f
10
;
50
;
100
;
200
g
.Tofindtheidealdimensionforvectors
A
i
and
T
i
,thevalueoftheadjustmentparameterissettobe0.7,
and

issettobe0.65.Weextractedthevenuesofidentifiedseed
papersandselectedthemasatargetnodetoruntheVVPNmodel
respectively,then,observedtheaverageperformanceoftheVVPN
modelintermsofMRRuponvariouscategories.Werepetitively
performedsuchexperimentswithvaryingrecommendationlists
inlengthtoevaluatetheinfluenceofthevectordimensionon
theresults.Weconductexperimentsonfourvaluesforvector
dimension(
k
),i.e.{10,50,100,200}.Itisobservedthatthemodel
performsbestwhenthevalueofthevectordimensionis100.
Table
8
representstheperformanceoftheVVPNmodelon
variousvectordimensions.Aswecansee,MRRscorekeepson
increasingandbehavingaconsistentperformancewhileincre-
mentingofvectordimension.Fromthewholepointofview,
themodelperformsalittlebetterwithvectordimension100.
Althoughwithvectordimension200itsresultswiththebest
performanceever.ThereisnosignificantimprovementinMRR
whilechangingthesizeof
k
from100to200.Asweknow,it
iscomputationallycostlyascomparedtovectordimension100.
Sowehaveconsideredthevectordimension(k)as100inour
experiment.
10.5.2.Influenceofadjustmentparameter(candm)
Inordertofindtheidealvalueof
m
togettheefficient
combinedscoreofvectors
A
i
and
T
i
,weconductexperiments
on10possiblevaluesforadjustmentparameter,i.e.{0.5,0.45,
0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05}.Thevalueofthevector
dimensionissetto100,and

issettobe0.65.Wehavefollowed
asimilarprocedure,asexplainedinSection
10.5.1
.
In
Table
9
,wecanobservethatthevariationtendencyof
MRRscoreperformsroughlyconsistent.WecanseethattheMRR
showsadownwardtrendwiththedecreasingvalueofadjust-
mentparameter1

m
.Themodelperformsthebestwhilethe
valueoftheadjustmentparameteris0.3.Thisisduetothecase
that,inmostofthecases,theabstractisgivingabetterclarityof
topicsimilaritywhileinsomeinstances,thetitleresultingbetter.
Soconsideringasimilarnature,inthisexperiment,thevalueof
(1

m
)and(1

c
)hasbeentakenas0.3.
10.5.3.InfluenceofT,andFinintra-graphclustering
Similarly,duringJarvis-Patrick,byvaryingthevalueof
T
,we
observedtheeffectonsub-clusterssizeandsimilarityamong
papersbelongtoeachsub-clusters.Weinvestigatetheperfor-
manceofsub-clustersfoundaftervaryingthresholdTas0.2,0.25,
0.3,0.35,0.4,0.45,0.5and0.55,andFas5,7,10,12,15,20,
30,and50whileperformingintra-graphclustering.Weobserved
that,whileconsideringTas0.5ormorethanthat,itresultsin
alargernumberofclusterswithlessnumberofpapersineach
sub-clusters.WealsosawthatduetohighT,chancesofforming
singletonclustersaremore.DuetothelowvalueofT,thereis
ahighchanceofforminglessnumberofclusterswithalarger
numberofpapersineachcluster.
Theaveragesimilarityamongpapersineachclusterisless
duetotheirlooselycoupledrelationship.Asimilarpatternis
shownbythevalueFduringintra-graphclustering.Weobserved
thatwiththevalueof
T
as0.35,resultingindesiredclusters
withhighaveragesimilarityamongpapersandalsoshowinga
tightlycoupledrelationship.Themodularityvalueobservedas
0.69.Thebestresultisfoundwithavalueof
F
as10duringthe
experimentation.
10.5.4.InfluenceofRinrecommendationofPPPN
Wefirstexaminewhetherincreasingthenumberofpapers
canproducedesiredrecommendationperformance.Wegradually
changedthevalueof
R
as5,8,10,12,15,and20,respectively.
Weobservedthat,after10papers,nosuchchangesareoccur-
ringintherecommendationorder.Thisisbecausemostsimilar
papersoccurinthelistoftop10andpapersthatarestrongly
coupledtothose10papersarealsoexhibitahighcontextual
similarityaswellastightlycoupledsemanticrelationship.After
applyingJarvis-Patrick,weobservedthat10papersaresufficient
tocapturemostsimilarpaperstorecommendappropriatevenues
asdiscussedinAlgorithm
2
.Wefoundthattherearenosuch
changesonthefinalrecommendationafterincreasingthevalue
ofR.Sofinally,thevalueof
R
isconsideredas10duringthe
experimentation.
10.5.5.Influenceoft
2
inrecommendationofPPPN
Wehavealsoexperimentallytestedtheeffectofthenumber
ofpapers(
t
2
)selectedfromSet-IItoperformabstractsimilar-
ity.Wefirstexaminewhetherincreasingthenumberofpapers
canproducedesiredrecommendationperformance.Wegradually
changedthevalueof
t
2
from5to45andnoticedthat,after15pa-
pers,therearenosuchchangesoccurringintherecommendation
order.Theupperlimitistakenas45toofferequalopportunityto
Set-IIpathalongwithSet-Ipath(papersfoundafterintra-graph
clustering)asonanaveragetheintra-graphclusteringresults
innumberofpapers.Ourproposedmodelisassumedto
recommendamaximumof15venues.
10.5.6.Influenceofdampingconstant(

)
Also,wemeasuredtheperformanceofCNAVERondamping
constant

.Thedampingconstant

isanimportantparameter
inRWR.Inordertofindtheidealvalueof

toperformthe
/>Page 16
----------------------------------------------------------------------------------------------------<16
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
Table8
Influenceofvectordimension(
k
)onMRR.
Topicdimension
MRR
2
<
D
v
c
<
88
<
D
v
c
<
1515
<
D
v
c
2
<
D
p
c
<
88
<
D
p
c
<
1515
<
D
v
c
100.05730.08810.09230.04950.07610.0982
500.06190.08930.10440.05620.08920.1016
1000.0932
0.0993
0.10970.08380.1038
0.1134
200
0.0946
0.0989
0.11040.08660.1039
0.1128
Table9
Influenceofadjustmentparameter(m)onMRR.
Adjustmentprob.(1

m
)
MRR
2
<
D
v
c
<
88
<
D
v
c
<
1515
<
D
v
c
2
<
D
p
c
<
88
<
D
p
c
<
1515
<
D
p
c
0.50.07930.08490.08530.08540.08610.0864
0.450.07980.08790.08510.08530.08930.0847
0.40.08670.09050.08930.09150.08410.0859
0.350.09720.08950.09490.08580.09030.0885
0.3
0.10930.11970.12670.11340.11270.1185
0.250.09720.10140.12580.10160.10390.1073
0.20.06680.08480.11320.08940.09170.0995
0.150.05260.07730.08660.07390.08770.0914
0.10.04730.06370.07250.06830.07460.0828
0.050.04370.05910.06830.05650.06770.0769
Table10
InfluenceofrestartprobabilityonMRR.
Restartprob.(1


)
MRR
2
<
D
v
c
<
88
<
D
v
c
<
1515
<
D
v
c
2
<
D
p
c
8
<
D
p
c
<
1515
<
D
p
c
0.50.06330.07290.11340.06350.08620.1067
0.450.07650.09140.10480.07140.09750.1095
0.40.09330.09750.10860.08370.10370.1135
0.35
0.13570.14320.17910.11370.11740.1248
0.30.11410.12650.14640.10890.11460.1195
0.250.09730.10120.12960.10190.10340.1078
0.20.07630.08470.11340.08960.09170.0995
0.150.05250.07720.08650.07340.08770.0918
0.10.04720.06360.07240.06870.07450.0823
0.050.04320.05940.06880.05630.06710.0766
randomwalkonvenue-venuegraph,weconductexperimentson
tenpossiblevaluesfordampingconstant,i.e.{0.5,0.45,0.4,0.35,
0.3,0.25,0.2,0.15,0.1,0.05}.Thevalueofthevectordimension
issetto100,andtheadjustmentparameterissettobe0.7.With
highervaluesof

,theprobabilityofrandomwalkerreachingfar
awayasthenumberofnodesincreases.Hence,thechancesof
gettingnewvenueswillbemore,butitmayresultinirrelevant
venues.
Itisevidentfrom
Table
10
thatthereisadrasticincrease
inMRRwhiledecreasingtheprobability(1


)till0.35.Af-
terward,itexhibitsadowntrendwiththedecreasingvalueof
dampingconstant.TheMRRscoreperformstheupperconvex
curve,rapidlyrisingwiththevalueof(1


)as0.35andthen
showsadeclineanddowntrendinperformance.Sobasedon
theabovestatistics,wehaveconsideredthevalueofdamping
constant(1


)as0.35intherestoftheexperiment.
10.6.Baselinemethods
Tomeasuretheeffectivenessoftheproposedvenuerecom-
mendation,wecompareourresultswitheightstate-of-the-art
methods.Detailedsettingsofthesystemsarepresentedbelow.
(a)
Friendbasedmodel(FB):Thebasicideaofthefriend-based
modelistorecommendvenuesasperthenumberofneigh-
borssuchasaresearchersco-authorandco-authorsco-
author.Ifmorefrequentlyavenueisrelatedtoneighbors,
thevenueisrecommendedtotheresearcher[
84
].
(b)
Collaborativefilteringmodel(CF):Itisbasedonthe
memory-basedcollaborativefilteringwithagivenpaper-
venuematrix.Theunderlyingassumptionisthatthereis
ahighprobabilityforapapertogetpublishedinvenues
whereothersimilarpapershavebeenpublished[
36
].
(c)
Co-authorshipnetwork-basedmodel(CN):Thismodelused
anewapproachthatbuildsasocialnetworkforeachau-
thorandthenrecommendsvenuesbasedontherepu-
tationoftheauthorssocialnetworkandotherinforma-
tionsuchasvenuename,venuessub-domain,numberof
publications[
21
].
(d)
Content-basedfilteringmodel(CBF):Themainideabe-
hindthisapproachistocomputethesimilaritybetween
researchersandvenues.Herewehavetakenresearchers
publicationandvenuespublicationscontentasfeaturevec-
torsrespectively,whicharecalculatedbyLDAmodel[
20
].
(e)
Randomwalkwithrestartmodel(RWR):Itrunsarandom
walkwithrestartmodelonaco-publicationnetworkwith
twotypesofnodes:authorsandvenues.Thismodelis
similartoAVER,buttheprobabilityofskippingtothenext
neighbornodeisequalinRWR[
28
].
(f)
Publicationrecommendersystem(PRS):Itisbasedona
newcontent-basedfiltering(CBF)recommendationmodel
usingchi-squareandsoftmaxregression.Itmainlyconsists
oftwomodules,suchasfeatureselectionmoduleand
softmaxregressionmodule[
30
].
(g)
Personalvenuerating-basedcollaborativefilteringmodel
(PVR):Itisbasedontheimplicitratinggiventoindi-
vidualvenues,createdfromreferencesofaresearchers
/>Page 17
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
17
Table11
PPPNandVVPNrecommendationperformanceintermsofaccuracyandMRR.
ApproachAcc@3Acc@6Acc@9Acc@12Acc@15MRR
FB0.05550.09720.12500.16660.19440.0338
CF0.09720.11110.15270.18050.23610.0451
CN0.11110.13880.18050.22220.25000.0516
CBF0.15270.18050.20830.23610.29160.0648
RWR0.19440.22220.25000.29160.31940.0775
PVR0.20830.23610.23680.31940.34720.0863
PRS0.20630.22910.24860.27930.34190.0875
PAVE0
:
2500
C
0
:
2916
C
0
:
3055
C
0
:
3611
C
0
:
4305
C
0
:
0906
C
PPPN
0.33340.36110.4027
0.47220.68050.1150
VVPN0.30550.34570.3888
0.51380.73610.1169
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
publicationsandthepaperswhichcitedresearcherspast
publications[
19
].
(h)
Personalizedacademicvenuerecommendationmodel
(PAVE):Itissimilartothepopularrandomwalkmodel
exceptforthedefinitionoftransfermatrixwithbias.The
probabilityofskippingtothenextneighbornodeisbi-
asedusingco-publicationfrequency,relationweight,and
researchersacademiclevelinPAVE[
22
].
AmongtheseeightmethodsCFandPVRarebasedoncollab-
orativefilteringapproach,PAVE,RWRisbasedonrandomwalk
withrestartalgorithmexploitingco-authorshipnetworks,CN,FB
isbasedonco-authorshipnetwork,andCBFandPRSarebased
oncontent-basedfilteringmethod.
11.Resultsanddiscussion
Inthissection,weevaluatetheeffectivenessofCNAVER
againstexistingstate-of-the-artmethods.Beforeassessingthe
performanceoftheproposedfusionmodelCNAVERindividual
performanceanalysisofPPPNmodelandVVPNmodelarean-
alyzedintwophasessuchasOfflineorCoarse-levelevaluation
andOnlineorFiner-levelevaluation.Duringtheassessment,best
resultsandthesecond-bestaremarkedby`bold-faceand`
C

symbolrespectively.
11.1.OfflineevaluationofPPPNmodel
ThecompleteresultsofaccuracyandMRRarepresentedin
Table
11
duringtheposition3,6,9,12,and15respectively.We
canseethatthePPPNmodelrevealstoaconsistentaccuracyover
allotherstate-of-the-artstrategies.Morethan33%ofthetime
(Acc@3
D
0.3334),itcanpredicttheoriginalvenueoftheseed
paperwithintop3recommendations.ThePPPNapproachshows
anaccuracyof0.6805whilerecommendingtop15recommen-
dations.FBstrategyexhibitsbadperformancewithanaccuracy
of0.1944whilerecommending15recommendations.Morethan
68%time,PPPNmodelcanpredicttheoriginalvenueoftheseed
paperwithintop15recommendation.
ForMRR,PPPNperformsexcellentbehavior(MRR0.1150).The
proposedapproachcanpredicttheoriginalvenueatearlyranks
comparedtoallothermethods.InthecaseofMRRalso,theleast
performanceisdemonstratedbytheFBmethod.
11.2.OnlineevaluationofPPPNmodel
Inthissection,weanalyzetheperformanceofthePPPNmodel
againstotherstate-of-the-artmethods.Theevaluationmetrics,
includingprecision,nDCG,andaveragevenuequality(H5-Index),
aretakenintoconsiderationthroughoutthisassessment.
Table12
PPPNandVVPNperformanceintermsofprecision.
MethodsP@3P@6P@9P@12P@15
FB0.56460.54930.53470.51160.5392
CF0.56560.58870.58890.59980.5885
CN0.61140.59940.60280.60030.5904
CBF0.61170.61130.61080.60080.6001
RWR0.65510.63170.62540.62730.6299
PRS0.66750
:
6976
C
0
:
6533
C
0.62050.6234
PVR0.65590.62480.62290.63180.6301
PAVE0
:
7005
C
0.68350.64920
:
6659
C
0
:
6678
C
PPPN
0.72430.7307
0.69480.66510.6509
VVPN0.69920.6998
0.72070.71140.7219
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
Table13
PPPNandVVPNperformanceintermsofnDCG.
MethodsnDCG@3nDCG@6nDCG@9nDCG@12nDCG@15
FB0.59130.57340.57430.57480.5786
CF0.61090.61980.62130.62310.6217
CN0.62550.63390.62960.63190.6325
CBF0.66710.65110.65170.65870.6639
RWR0.65890.65840.65270.65920.6657
PRS0.65490.65850.66910.66040.6695
PVR0.66120.66720.66320.66370.6543
PAVE0
:
6759
C
0
:
6691
C
0
:
6701
C
0
:
6749
C
0
:
6771
C
PPPN
0.69390.70130.6939
0.66890.6706
VVPN0.65840.66990.6892
0.72090.7425
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
11.2.1.Precision@k
In
Fig.
4
,wecanseethesignificanceofthePPPNmodelasfar
asprecision@kandnDCG@koverallotherstandardapproaches.
ThePPPNmodelexhibitsthehighestprecisionof0.7348atposi-
tion4,andafterthat,itmarginallydowngradesandfurthermore
achievesaprecisionabout0.6775atposition11asdepicted
in
Fig.
4(a)
.ThePPPNmodelperformssuperioruntiltheinitial
11recommendations.Afterward,itshowsadescendingpattern
becauseofwhichitisunabletomaintainconsistencyasdepicted
in
Table
12
.Thismodeldemonstratesalowerprecisionof0.6531
atposition13.
Forthefirstvenue,PPPNaccomplishesthehighestprecision
amongallothermethods.Lateron,thoseprecisioncontinues
diminishingandfurthermoreachievesaprecisionabout0.6509
atposition15.PAVEmethodindicateshigherperformanceover
PPPNmodelatposition12,13,14,and15respectively.The
worstperformanceamongallmethodsisdemonstratedbythe
FBmethod.
11.2.2.nDCG@k
TheoverallnDCG@kofallmethodsareshownin
Table
13
.
ThroughoutnDCG@kevaluation,PPPNmodeldemonstratessu-
periorscoresoverallotherstate-of-the-artmethods.ThePPPN
modelperformsanupwardtrendandfurthermoreachievesthe
mostastoundingnDCG0.7013duringposition6,alsosubse-
quentlyagain,itrevealstoadescendingpatternandshowsnDCG
of0.6685atposition13.Afterward,itgraduallyincreasesand
accomplishesadecentnDCG0.6706atposition15,asdepicted
in
Fig.
4(b)
.
11.2.3.Averagevenuequality(H5-Index)analysis
Wehaveadditionallyassessedthequalityofvenuesrecom-
mendedbyPPPNmodelascomparedtootherexistingmethod-
ologies.ThePPPNmodeloutperformsothermethodsinterms
ofaverageH5-Indexofrecommendedvenues,asillustratedin
Fig.
5(a)
.Whileassessingaveragevenuequality,thePPPNmodel
performsanupwardtrendfromthebeginningandshowsan
/>Page 18
----------------------------------------------------------------------------------------------------<18
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
Fig.4.
PPPNrecommendationperformanceintermsofprecision@kandnDCG@k.
Fig.5.
PPPNandVVPNperformanceintermsofaveragevenuequality.
overallaverageH5-Indexabout49.Thetop-qualityvenuesrec-
ommendedbyPPPNisinposition7withthehighestH5-Indexof
59.Thenitindicatesadescendingpatternfurthermoreachieves
anH5-Indexofvalue40atposition15,asshownin
Fig.
5(a)
.The
lowestqualityofvenuesrecommendedbytheFBmethodwith
anaverageH5-Indexof30,whereasthesecond-highestquality
venuesrecommendedbyPAVEmodelwithanaverageH5-Index
about43.
11.3.OfflineevaluationofVVPNmodel
VVPNmodelshowsaconsistentaccuracyoverallotherstan-
dardapproaches(
Table
11
).Morethan30%timeitcanpredict
theoriginalvenueoftheseedpaperwithinthetop3recommen-
dations.Initially,theVVPNmodelshowsanaccuracyof0.3457at
position6.Thenslowlyitshowsanupwardtrendandexhibitsan
excellentperformancewithanaccuracyof0.7361atposition15.
VVPNalsoshowsexcellentperformanceoverotherstandard
approachesintermsofMRR.VVPNmodelexhibitstheoverall
MRRof0.1169.Thesecond-bestperformanceisshownbythe
PAVEmodelwithMRR0.0906.Theproposedapproachcouldpre-
dicttheoriginalvenueatearlyrecommendationsascomparedto
allothermethods.InthecaseofMRRalso,theleastperformance
isexhibitedbytheFBmethod.
11.4.OnlineevaluationofVVPNmodel
Weevaluateatafinerlevel,theeffectofVVPNrecommenda-
tionsandcompareitagainstotherstate-of-the-artmethods.We
usevariousmetricssuchasprecision,nDCG,andaveragevenue
quality(H5-Index),respectively.
11.4.1.Precision@k
Thecomparedresultsareshownin
Fig.
6
.Itcanbeeasily
observedthattheproposedapproachVVPNmodelhasmadea
significantimprovementofprecision@koverthestandardap-
proachesasdepictedin
Fig.
6(a)
.Initially,theVVPNmodelshows
aprecisionof0.7132ataposition2.Thenitslowlyindicatesa
downwardtrendandreachesaprecisionof0.6998atposition6
asdepictedin
Table
12
.
Butafterward,itshowsanupwardtrendandshowsthehigh-
estprecisionof0.7219atposition15andleastprecisionvalueof
0.6804afterrecommending5recommendations.ThePRSmodel
showsthesecond-bestperformanceatposition5,6,and7re-
spectively.PAVEexhibitsexcellentperformanceatposition1,2,
3and4respectively.Theworstperformanceamongallmethods
isshownbytheFBmethod.
11.4.2.nDCG@k
TheoverallnDCGscoresareshownin
Table
13
.Initially,the
VVPNmodelshowsalowernDCG0.6587atposition2.Then
slowlyitshowsadownwardtrendandreachesthenDCG0.6578
atposition5.Afterward,itshowsanupwardtrendandisableto
showconsistencyatotherpositionsoftherecommendations.It
isclearlyshownin
Fig.
6(b)
thatthegraphofVVPNisconsistent
afterrecommending5venuesandshowsanDCG0
:
7209atposi-
tion12.ButmethodPAVEshowshighernDCGthanVVPNmodel
atposition1,2,3,4and5respectively.Itconsistentlyshowsthe
second-bestperformancethroughout.TheFBmodelexhibitsthe
worstperformance.
/>Page 19
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
19
Fig.6.
VVPNrecommendationperformanceintermsofprecision@kandnDCG@k.
Table14
AccuracyandMRRresultsofCNAVERandothercomparedapproaches.
ApproachAcc@3Acc@6Acc@9Acc@12Acc@15MRR
FB0.05550.09720.12500.16660.19440.0338
CF0.09720.11110.15270.18050.23610.0451
CN0.11110.13880.18050.22220.25000.0516
CBF0.15270.18050.20830.23610.29160.0648
RWR0.19440.22220.25000.29160.31940.0775
PVR0.20830.23610.23680.31940.34720.0863
PRS0.20630.22910.24860.27930.34190.0875
PAVE0
:
2500
C
0
:
2916
C
0
:
3055
C
0
:
3611
C
0
:
4305
C
0
:
0906
C
CNAVER0.35720.38880.45830.58330.79160.1402
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
11.4.3.Averagevenuequality(H5-Index)analysis
Weinvestigatetheperformanceofvenuequalityrecommended
byVVPNascomparedtootherexistingapproaches.VVPNmodel
outperformsothermethodsintermsofaverageH5-Indexof
recommendedvenues.Overall,theaverageH5-Indexofvenues
recommendedbytheVVPNmodelis45.Thetop-qualityvenues
recommendedbyVVPNareatposition11withthehighest
H5-Indexof51asdisplayedin
Fig.
5(b)
.
11.5.Offlineevaluationoffusionmodel:CNAVER
ThecompleteresultsofaccuracyandMRRafterfusionare
depictedin
Table
14
.Itisevidentfromtheoverallresultsof
accuracyandMRRthattheproposedapproachCNAVERshowsa
consistentperformanceoverallotherstandardapproaches.More
than35%ofthetimeitcanpredicttheoriginalvenueoftheseed
paperwithinthetop3recommendations.
Theproposedapproachshowsanaccuracyof0.7916after
recommendingthetop15recommendations.Similarly,during
theevaluationofMRR,wecanseethatCNAVERoutperforms
allotherstate-of-the-artmethodsandshowsexcellentbehav-
iorwithaMRR0.1402.Theproposedapproachcanpredictthe
originalvenueatearlyrecommendationsbetterthanallother
methods.Thesecond-bestperformanceisexhibitedbythePAVE,
whereastheFBperformstheworstamongalldifferentstandard
approaches.
Wehavealsoinvestigatedtheefficacyoftheproposedmodel
CNAVERintermsof
F

measure
macro
(
F
1
)againstotherstate-
of-the-artmethods.Thecompleteresultsof
F

measure
macro
are
shownin
Table
15
.
F
1
scoresaregenerallyseentoincreasewith
rankuptoacertainpoint(aroundanddropthereafter.This
ispossiblyduetothefactthatprecisionandrecallbothincrease
tillthatpointuntiltheoriginalvenuesareretrieved,causingan
increasein
F
1
score.However,withfurtherincreaseinranks,
Table15
Macro-averageanalysisintermsof
F

measure
macro
(
F
1
).
Approach
F
1
@3
F
1
@6
F
1
@9
F
1
@12
F
1
@15
FB0.01280.02310.04580.04120.0408
CF0.03510.04370.07590.06940.0621
CN0.05610.06720.10450.10040.0938
CBF0.08940.10250.12890.11670.1125
RWR0.11480.14130.21410.18940.1663
PVR0.12970.15680.18540.19450.1867
PRS0.12310.14560.19590.18890.1826
PAVE0
:
1631
C
0
:
2012
C
0
:
2674
C
0
:
2248
C
0
:
2179
C
CNAVER0.27690.31790.36270.35610.3524
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
precisiondropssharplywithoutmuchincreaseinrecallleading
toanoveralldropin
F
1
scores.HerealsoCNAVERdemonstrates
theefficacyincomparisontootherstate-of-the-artmethods.
Thesecond-bestperformanceisexhibitedbyPAVE,whereasFB
performstheworst.
11.6.Onlineevaluationoffusionmodel:CNAVER
Inthissection,theperformanceofCNAVERagainstother
state-of-the-artmethodsisdiscussed.Wedemonstratetheper-
formanceoftheproposedsystemconsideringvariousevalua-
tionmetricssuchasprecision,nDCG,andaveragevenuequality
(H5-Index),respectively.
11.6.1.Precision@k
TheoverallresultsprecisionandnDCGevaluationsareshown
in
Fig.
7
.In
Fig.
7(a)
,wecanseethesignificanceofCNAVERin
termsofprecisionoverallotherstandardapproaches.Initially,
theproposedCNAVERexhibitsaprecisionof0.7456atposition
2,andafterthat,itslightlyshowsanupwardtrendandshowsa
precisionof0.7634atposition9(
Table
16
).
TheproposedmodelCNAVERexhibitsthehighestprecision
of0.7704afterrecommending15recommendations.Itshows
alowerprecisionof0.7449atposition1.Similarly,thePAVE
methodperformsthesecond-bestatpositions1,2,3and4
respectively.PRSmethodexhibitsslightlyhigherprecisionthan
thePAVEmethodatposition5,6,7and9respectively.Theworst
performanceamongallmethodsisshownbythe
FB
method.
11.6.2.nDCG@k
ThenDCG@kevaluationsofallmethodsareshownin
Ta-
ble
17
.ProposedCNAVERalsoexhibitsbetternDCGscoresover
allotherstate-of-the-artmethods.TheCNAVERmodelperforms
/>Page 20
----------------------------------------------------------------------------------------------------<20
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
Fig.7.
CNAVERperformanceintermsofprecision@kandnDCG@k.
Table16
PrecisionofCNAVERandothercomparedapproaches.
MethodsP@3P@6P@9P@12P@15
FB0.56460.54930.53470.51160.5392
CF0.56560.58870.58890.59980.5885
CN0.61140.59940.60280.60030.5904
CBF0.61170.61130.61080.60080.6001
RWR0.65510.63170.62540.62730.6299
PRS0.66750
:
6976
C
0
:
6533
C
0.62050.6234
PVR0.65590.62480.62290.63180.6301
PAVE0
:
7005
C
0.68350.64920
:
6659
C
0
:
6678
C
CNAVER0.76940.76870.76340.76290.7704
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
Table17
nDCGofCNAVERandothercomparedapproaches.
MethodsnDCG@3nDCG@6nDCG@9nDCG@12nDCG@15
FB0.59130.57340.57430.57480.5786
CF0.61090.61980.62130.62310.6217
CN0.65540.63390.62960.63190.6325
CBF0.66710.65110.65170.65870.6639
RWR0.65890.65840.65270.65920.6657
PRS0.65490.65850.66910.66040.6695
PVR0
:
6612
C
0.66720.66320.66370.6643
PAVE0.65990
:
6691
C
0
:
6701
C
0
:
6749
C
0
:
6771
C
CNAVER0.72830.72470.72350.74670.7511
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
anupwardtrendandreachesanDCG0.7359atposition8,and
afterward,itshowsanupwardtrendandreachesnDCG0.7611
atposition15(
Fig.
7(b)
).TheperformanceofCNAVERiscon-
sistentandshowsthehighestnDCG0.7746atposition12.The
PAVEmodeldemonstratesthesecond-bestperformance.TheFB
modelshowstheworstperformanceamongallotherstandard
approaches.
11.6.3.Averagevenuequality(H5-Index)analysis
Wealsoinvestigatetheperformanceofvenuequalityrecom-
mendedbyCNAVERascomparedtootherexistingapproaches.
CNAVERoutperformsothermethodsintermsofaverageH5-
Indexofrecommendedvenuesasdepictedin
Table
18
.Overall,
theaverageH5-IndexofvenuesrecommendedbyCNAVERis54.
Thetop-qualityvenuesrecommendedbyCNAVERareatposition
7withthehighestH5-Indexof63asdisplayedin
Fig.
8
.
11.6.4.Evaluationofdiversity
Diversityisdefinedintermsofcontentdissimilarity.Wegroup
allpaperspublishedataparticularvenueandextracttheircor-
respondingkeywords.Weapplythesimilarityscoretodefine
Table18
H5-IndexofCNAVERandothercomparedapproaches.
ApproachHI@3HI@6HI@9HI@12HI@15
FB3636262322
CF3538312922
CN3133273426
CBF2939313529
PRS3942363531
RWR44
C
44323636
PVR4145344133
PAVE4248
C
41
C
43
C
43
C
CNAVER5158525253
Bestresultsarehighlightedinbold,and2ndbestaremarkedby(`
C
).
Fig.8.
AveragevenuequalityofCNAVERandotherapproaches.
diversityinEq.
(
49
)
,andthescoresarein
Table
19
.CNAVER
isseentoshowthebestdiversity,whereasthesecond-best
performeristhemethodPVR.
11.6.5.Evaluationofstability
Wehavealsoprovidedacomprehensiveinvestigationofthe
stabilityofCNAVERasdefinedinEq.
(
50
)
.CNAVERshowslower
MASthanallotherstandardapproaches(
Table
20
).Itshows
aMASof4.359ontheDBLPdataset,meaningthatonanav-
erageeverypredictedvenuewillshiftbyapositionof4.359
afteraddingnewdataintothetrainingdataofthesystem.We
haveconsideredtheaverageMAS-scoreasathresholdtodecide
whetheraparticularmethodprovidesstabilityornot.
11.6.6.Statisticalsignificancetest
ToseethedifferencebetweentheperformanceofCNAVERand
thesecondbestissignificantornot,wedidpaired-samplest-test.
/>Page 21
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
21
Table19
Diversity(D)ofCNAVERandotherapproaches.
MethodsDiversity(D)
FB0.219
CF0.338
CN0.273
CBF0.204
RWR0.309
PVR0
:
394
C
PRS0.273
PAVE0.316
CNAVER0.497
Bestresultsand2ndbestaremarkedbybold,and(`
C
).
Table20
Stability(MAS)ofCNAVERandotherapproaches.
MethodsMAS
FB9.821
CF8.757
CN9.452
CBF5.769
RWR7.884
PVR8.236
PRS5
:
351
C
PAVE8.349
CNAVER
4.359*
Bestresultsand2ndbestaremarkedbybold,and(`
C
).
Itdetermineswhetherthereisstatisticalevidencethatthemean
differencebetweenpairedobservationsonaparticularoutcome
issignificantlydifferentfromzero.Thisisaparametrictestdone
usingt-statisticasdefinedbelow.
t
D
m
s
=
p
n
(53)
Where
m
and
s
denotethemeanandstandarddeviationofthe
differencesbetweenallpairs.Here,
n
denotesthesizeofthe
samplespace.
Foratwo-sidedtestthenullandalternativehypothesisare
consideredthefollowingway.
H
0
:

d
=0(Truemeandifferenceisequaltozero)
H
1
:

d
6D
0(Truemeandifferenceisnotequaltozero)
Toclaimsuperiority(orinferiority)ofasystemoveranother,
one-sidedtestisdonewhere
H
0
remainsthesame,but
H
1
is
modifiedasfollows.
H
1
:

d
>
(or
<
)0
Underthenullhypothesis,thisstatisticissupposedtofollow
at-distributionwith
n

1degreesoffreedom(df).Ifthe
p
-value
ismuchlessthan
x
(here
x
D
0
:
01
;
0
:
05
;
0
:
1)thenwecanreject
thenullhypothesis(
H
0
)infavorofalternativehypothesis(
H
1
).
Weperformedone-sidedtest(

d
D

1


2
>
0)on
overallprecision,nDCG,accuracy,MRR,
F

measure
macro
,average
venuequality,anddiversityandone-sidedtest(

d
D

1


2
<
0)intermsofstabilitytovalidatethesignificanceof
proposedCNAVERagainstotherstate-of-the-artmethods.During
thetest,wehavecomparedthepairedsamplest-testsresultsat
positions3,6,9,12,and15,respectively.Itrequired120pairwise
comparisons(
df
D
119)foreachpositionduringtheevaluation.
Thestatisticallysignificantresultsarehighlightedinthestar
annotatedsymbolateachposition.TheproposedmodelCNAVER
consistentlyoutperformsotherapproaches,andthedifferences
arestatisticallysignificant,asdepictedin
Tables
22

28
.
12.Studyoftheproposedapproach
ThemainfindingsconcerningourSQsasintroducedinSec-
tion
10.4.1
aresummarizedbelow:
12.1.
SQ1
:HoweffectiveisCNAVERincomparisontootherstate-of-
the-artmethods?
TheoverallresultsofCNAVERandotherstate-of-the-artmeth-
odsaredisplayedin
Tables
14
,
15
,
16
,and
17
respectively.
Itdemonstratesthebestperformanceintermsofprecision@k,
nDCG@k,accuracy,MRR,and
F

measure
macro
,respectively.Also,
thedifferencewiththesecond-bestisstatisticallysignificanteven
at1%levelofsignificance.
12.2.
SQ2
:HowisthequalityofvenuesrecommendedbyCNAVER
ascomparedtostate-of-the-artmethods?
ThecompleteresultsofvenuequalityintermsofH5-Indexis
depictedin
Table
18
.ThevenuesrecommendedbyCNAVERareof
highqualitywhencontrastedwithothercuttingedgetechniques
asportrayedin
Fig.
8
.TheaverageH5-indexofCNAVERis54
afterrecommending15venues.PAVErecommendsvenueshaving
thesecond-bestH5-index.Theleastqualityofrecommendation
performedbytheFBmodel.ThemostelevatedH5-indexrecom-
mendedbyCNAVERis63,andtheleastis46,whereasthemost
noteworthyH5-indexsuggestedbythesecond-bestPAVEis48
andtheleastis37.
12.3.
SQ3
:HowdoesCNAVERhandlecold-startissuesandother
issueslikedatasparsity,diversity,andstability
(i)
Cold-startissues
:Tospecificallyaddress``cold-startis-
sueslikeanewresearcherandanewvenue,PPPNand
VVPNarefusedtogivevenuerecommenderframework
customizableforpersonalization.Examinationof
Tables
9
and
10
revealthat,regardlessofwhethertheseedpa-
peridentifiedwiththenewresearcherandnewvenue,
CNAVERcanpredicttheoriginalvenueatanearlystage
ofrecommendations.Itdoesnotrequirepastpublication
recordsorco-authorshipnetworksfortherecommenda-
tions.Ratheritonlyfocusesontheworkathand.Itcon-
sidersonlythecurrentareaofinterestalongwiththetitle,
andabstractasinputstorecommendthesame.
(ii)
Datasparsity
:Toexplicitlyaddressthedatasparsityissue,
bothimportanceandrelevanceparametersareconsidered
atthebeginningphaseoftheproposedmethod.Social
networkanalysisthroughdifferentcentralitymeasuresand
contentfeatureslikeabstractandtitlewereusedtocapture
thequalityofessentiality,relevance,andimportancesep-
arately.Toextractonlyrelatedpapers,theentirecitation
networkisapportioned,andlateron,intra-graphclustering
isperformed.Sogiventheseedpaper,justessentialand
relevantpapersarefilteredfromthesub-clusters.Ithas
beennoticedthatthenumberofpapersfoundaftercen-
tralitymeasuresarearound32,069outoftotal2,236,968
papersasinput.Theaveragenumberofpapersinvolved
afterIntra-graphclusteringforabstractsimilarityisinthe
rangeofAftertheinitialstep,weareleftwith
importantpapersforfurthercomputation,whichisclose
totheareaofinterest.Hencethereisnodatasparsityissue
inourproposedapproach,asindicatedin
Table
21
.
(iii)
Diversity
:Toresolvetheissueofdiversity,bothconnec-
tionandcontextualsimilarity-basedrelevanceparame-
tersaretakenintoconsideration.Mainlyage-discounted
Venue2Vec,meta-pathfeatures,andbiasedrandomwalk
areincorporatedinVVPNtorecommendvenuesfrom
diversepublishers.1-degreeand2-degreemeta-pathscap-
turedifferentrichlatentinformationinVVPNmodel.In
thePPPNmodel,topicmodelingalongsideintra-graphclus-
teringcapturesbothcontextsaswellaslinkstosuggest
/>Page 22
----------------------------------------------------------------------------------------------------<22
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
Table21
Cold-startandotherissuesavailableinCNAVERandotherapproaches.
MethodsCold-startSparsityDiversityStability
FByes(newresearcher)noyesyes
CFyes(researcherandvenue)yesnoyes
CNyes(newvenue)noyesyes
CBFyes(newvenue)noyesno
RWRyes(newresearcher)noyesyes
PRSyes(newvenue)noyesno
PVRyes(researcherandvenue)yesnoyes
PAVEyes(newresearcher)noyesyes
CNAVER
nononono
Table22
pvaluesofpairedt-testwithCNAVER(Precision).
MethodsP@3P@6P@9P@12P@15
FB0.00011
*
0.00008
*
0.00004
*
0.00002
*
0.00006
*
CF0.000130.00016
*
0.00015
*
0.00019
*
0.00015
*
CN0.00023
*
0.00016
*
0.00019
*
0.00021
*
0.00014
*
CBF0.00023
*
0.00021
*
0.00020
*
0.00017
*
0.00013
*
RWR0.00035
*
0.00029
*
0.00024
*
0.00026
*
0.00021
*
PRS0.00039
*
0.00057
*
0.00038
*
0.00027
*
0.00022
*
PVR0.00036
*
0.00026
*
0.00023
*
0.00029
*
0.00027
*
PAVE0.00053
*
0.00046
*
0.00031
*
0.00039
*
0.00037
*
*pvaluesarestatisticallysignificantat

D
0
:
05.
Table23
pvaluesofpairedt-testwithCNAVER(nDCG).
MethodsnDCG@3nDCG@6nDCG@9nDCG@12nDCG@15
FB0.00023
*
0.00012
*
0.00009
*
0.00003
*
0.00005
*
CF0.00025
*
0.00027
*
0.00031
*
0.00020
*
0.00017
*
CN0.00031
*
0.00039
*
0.00037
*
0.00024
*
0.00017
*
CBF0.00052
*
0.00045
*
0.00041
*
0.00032
*
0.00038
*
RWR0.00049
*
0.00053
*
0.00048
*
0.00052
*
0.00036
*
PRS0.00045
*
0.00043
*
0.00048
*
0.00029
*
0.00033
*
PVR0.00051
*
0.00049
*
0.00053
*
0.00032
*
0.00031
*
PAVE0.00065
*
0.00057
*
0.00062
*
0.00041
*
0.00049
*
*pvaluesarestatisticallysignificantat

D
0
:
05.
relevantpapersfromdiversepublishers.CNAVER,therefore
showsthehighestvalueof
D
(diversity)ascomparedtoall
otherapproaches(
Table
19
).
(iv)
Stability
:Todealwiththestabilityissue,aseriesoftech-
niquesareused,broadlydividedintotwoclasses:PPPNand
VVPN-whicharefinallyfusedtogethertoprovideasingle
rankedlistofrecommendations.BothPPPNandVVPNare
apipelineoftechniqueswherepapersarefilteredand/or
addedtoenrichthepoolofshortlistedpapers.Techniques
likecontent-similarity,variouscentralitymeasures,meta-
path,randomwalkareusedtoinvitediversityaswellas
robustnesstothesystem.Eachofthesetechniquespar-
ticipatesinaco-operativemannerwherethecontribu-
tionofanysingletechniqueisnotimmenselydecisive.
Rather,wehavesomeamountofredundancysuchthat
apaperispotentiallyshortlistedbyseveraltechniques.
Tocounterthedestabilizingnatureofnetwork-basedap-
proaches,content-basedapproachesareincorporatedat
severalplacesinthepipeline.Inall,thesebatteriesoftech-
niquestogetherprovidestabilitytotherecommendations.
CNAVERshowstheminimumMASthanallotherstandard
approaches(
Table
20
).
12.4.Moreinsightfuldiscussionontheresults
Theoverallperformanceresultsobtainedanddiscussedin
Section
11
showcasetheefficacyoftheproposedCNAVER.The
Table24
pvaluesofpairedt-testwithCNAVER(AccuracyandMRR).
ApproachAcc@3Acc@6Acc@9Acc@12Acc@15MRR
FB0.00009
*
0.00013
*
0.00010
*
0.00008
*
0.00001
*
0.00103
*
CF0.00011
*
0.00010
*
0.00011
*
0.00008
*
0.00003
*
0.00123
*
CN0.00013
*
0.00012
*
0.00014
*
0.00008
*
0.00005
*
0.00218
*
CBF0.00012
*
0.00013
*
0.00011
*
0.00009
*
0.00006
*
0.00276
*
RWR0.00016
*
0.00017
*
0.00015
*
0.00011
*
0.00007
*
0.00318
*
PRS0.00022
*
0.00017
*
0.00013
*
0.00011
*
0.00009
*
0.00047
*
PVR0.00021
*
0.00023
*
0.00013
*
0.00016
*
0.00007
*
0.00446
*
PAVE0.00057
*
0.00065
*
0.00043
*
0.00039
*
0.00012
*
0.00594
*
*pvaluesarestatisticallysignificantat

D
0
:
05.
Table25
pvaluesofpairedt-testwithCNAVER(
F
1
).
Approach
F
1
@3
F
1
@6
F
1
@9
F
1
@12
F
1
@15
FB0.00009
*
0.00013
*
0.00010
*
0.00008
*
0.00001
*
CF0.00011
*
0.00010
*
0.00011
*
0.00008
*
0.00003
*
CN0.00013
*
0.00012
*
0.00014
*
0.00008
*
0.00005
*
CBF0.00012
*
0.00013
*
0.00011
*
0.00009
*
0.00006
*
RWR0.00016
*
0.00017
*
0.00015
*
0.00011
*
0.00007
*
PRS0.00022
*
0.00017
*
0.00013
*
0.00011
*
0.00009
*
PVR0.00021
*
0.00023
*
0.00013
*
0.00016
*
0.00007
*
PAVE0.00061
*
0.00063
*
0.00057
*
0.00051
*
0.00047
*
*pvaluesarestatisticallysignificantat

D
0
:
05.
Table26
pvaluesofpairedt-testwithCNAVER(HI:H5-Index).
ApproachHI@3HI@6HI@9HI@12HI@15
FB0.00037
*
0.00012
*
0.00014
*
0.00011
*
0.00009
*
CF0.00032
*
0.00024
*
0.00019
*
0.00016
*
0.00015
*
CN0.00034
*
0.00017
*
0.00014
*
0.00011
*
0.00007
*
CBF0.00017
*
0.00023
*
0.00019
*
0.00025
*
0.00012
*
RWR0.00059
*
0.00034
*
0.00029
*
0.00039
*
0.00034
*
PRS0.00031
*
0.00026
*
0.00027
*
0.00023
*
0.00016
*
PVR0.00036
*
0.00027
*
0.00019
*
0.00016
*
0.00007
*
PAVE0.00042
*
0.00038
*
0.00034
*
0.00043
*
0.00036
*
*pvaluesarestatisticallysignificantat

D
0
:
05.
excellentoverallprecisionimpliesthatthemodelscaneffec-
tivelyrecommendtherelevantvenues.However,thereareafew
limitationsofourwork.
(i)
Theproposedsystemhasmultipleparametersinvolvedin
bothPPPNandVVPNmodels.Mostofthestepsinvolvedin
thePPPNmodelarepurelybasedonempiricalassumptions
butbackedbyobservationsfromrigorousexperimentation.
(ii)
Ifthetopmost
R
paperssimilartoagivenseedpaper
arelooselycoupledinthebibliographiccitationnetwork,
Jarvis-Patrickmaycreateclusterswithlessnumberofre-
latedpapers.Hence,theproposedmodelCNAVERmay
failtocapturetherelevantpapersresultinginpossibly
irrelevantvenuerecommendations.
(iii)
IntheVVPNmodel,whilechoosingthevenueofinterest
(
Z
)ifthetopmostpaperiscontextuallysimilarwiththe
seedpaperbutitscorrespondingvenueassociatedwith
entirelydifferentdomainsthenfewofthetopmostrecom-
mendationsbyrandomwalkalgorithmmaynotberele-
vant.
(iv)
Iftheoriginalvenueofaseedpaperiscomparativelynew
andthevenuedoesnothavesufficientnumberpapers,the
systemmayperformpoorly.Althoughthevenueofinterest
Z
iscontextuallysimilarincontentbutduetometa-paths
featuresaggregation,othervenuesmayberecommended
intheVVPNmodel,buttheoriginalvenuemaynotappear
atthetopoftherecommendationlist.Hence,itmayresults
inlowaccuracyandlowMRRduringon-lineevaluation.
/>Page 23
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
23
Table27
pvaluesofpairedt-testwithCNAVER(Diversity).
MethodsDiversity(D)
FB0.00008
*
CF0.00019
*
CN0.00013
*
CBF0.00009
*
RWR0.00021
*
PVR0.00047
*
PRS0.00018
*
PAVE0.00025
*
*pvaluesarestatisticallysignificantat

D
0
:
05
Table28
pvaluesofpairedt-testwithCNAVER(Stability).
MethodsStability(MAS)
FB0.00024
*
CF0.00046
*
CN0.00032
*
CBF0.00089
*
RWR0.00073
*
PVR0.00053
*
PRS0.00095
*
PAVE0.00046
*
*pvaluesarestatisticallysignificantat

D
0
:
05
13.Conclusionandfuturework
Academicvenuerecommendationisanemergingareaofre-
searchinrecommendationsystems.Theprevalenttechniquesare
fewinnumbersandsufferfromvariouslimitations.Oneofthe
majorissuesisthatofcold-starthavingtwosub-parts:anew
venueandanewresearcher.Additionally,thereexistproblemsof
sparsity,diversity,andstabilityinvenuerecommendersystems
thatarenotadequatelyaddressedinexistingstate-of-the-art
methods.
Weproposedafusion-basedscholarlyvenuerecommender
systemCNAVERincorporatingpaper-paperpeernetwork(PPPN)
modelandvenue-venuepeernetwork(VVPN)modelthatreason-
ablyaddressestheabove-mentionedissues.Severaltechniques
liketopicmodelingbasedcontextualsimilarity,linkanalysis,and
topic-orientedintra-graphclustering,abstractsimilarityusing
OkapiBM25
C
algorithmareusedtoreinforcethePPPNmodel.To
identifyrelevantvenues,age-discountedbasedVenue2Vec,dif-
ferentmeta-pathsfeatures,andbiasedrandomwalkwithrestart
(RWR)algorithmareincorporatedintotheVVPNmodel.
Weconductedanextensivesetofexperimentsonareal
datasetDBLPandshowedthatCNAVERconsistentlyoutperforms
state-of-the-artmethods.Itshowssubstantiallyhigherscoresof
precision@k,nDCG@k,accuracy,MRR,
F

measure
macro
,diver-
sityandstabilitythanotherbestinclasstechniques.CNAVER
proposestop-notchvenueswhencontrastedwithcuttingedge
techniquesasfarasH5-index.
Nonetheless,thereisscopeforcontinuousupdateofthe
model.Consideringthefastdevelopmentofdigitalinformation
technology,wewouldliketoemployawebcrawlertoupdate
thetrainingdatasetandthelearningmodelcontinuously.This
crawlerwillautomaticallyextractandcollecttherelevantdatato
generatethetrainingdataset.Tocontinuallyenhancethequality
oftherecommendationofCNAVER,weplantocollectfeedback
fromusersthroughaweb-basedapplication.Weplantoadopt
someinformationretrievaltechniqueslikerelevancefeedback,
orpseudorelevancefeedbacktoimprovetherelevanceoffinal
recommendations.Inthefuture,wewouldliketoincorporate
advancedmachinelearningtechniquessuchasgradientdescent
optimization,etc.,insuchawaythatitwillenforcetherandom
walkernottogotoofarfromtheinitialvenueofinterest(
Z
).
Weintendtoexplorewithdifferentdatasetsandtobroaden
itforvariouscontrolswiththeobjectiveofenhancingprecision,
accuracy,diversity,novelty,coverage,andserendipity.Wewould
liketoexplorethesamewiththeassistanceofheterogeneous
bibliographicdatacoordinatewithallconceivablemeta-paths(till
degreefour)highlightstorecommendscholarlyvenues.
14.Compliancewithethicalstandards
Theauthorsdeclarenoconflictsofinterest.Thearticleutilizes
arankbasedfusionmodelCNAVERexploitingpaper-paperpeer
network(PPPN)modelandvenue-venuepeernetwork(VVPN)
modeltorecommendpublicationvenuesforaresearcher.The
articledoesnotcontainanyexaminationswithhumanorcreature
subjects.
References
[1]
D.Liang,L.Charlin,J.McInerney,D.M.Blei,Modelinguserexposurein
recommendation,in:Proceedingsofthe25thInternationalConferenceon
WorldWideWeb,InternationalWorldWideWebConferencesSteering
Committee,2016,pp.
[2]
G.Adomavicius,A.Tuzhilin,Towardthenextgenerationofrecommender
systems:Asurveyofthestate-of-the-artandpossibleextensions,IEEE
Trans.Knowl.DataEng.17(6)(2005)
[3]
J.Bobadilla,F.Ortega,A.Hernando,A.Gutirrez,Recommendersystems
survey,Knowl.-BasedSyst.46(2013)
[4]
J.Tang,S.Wu,J.Sun,H.Su,Cross-domaincollaborationrecommendation,
in:Proceedingsofthe18thACMSIGKDDInternationalConferenceon
KnowledgeDiscoveryandDataMining,ACM,2012,pp.
[5]
S.Cohen,L.Ebel,Recommendingcollaboratorsusingkeywords,in:Pro-
ceedingsofthe22ndInternationalConferenceonWorldWideWeb,ACM,
2013,pp.
[6]
P.Chaiwanarom,C.Lursinsap,Collaboratorrecommendationininter-
disciplinarycomputerscienceusingdegreesofcollaborativeforces,
temporalevolutionofresearchinterest,andcomparativesenioritystatus,
Knowl.-BasedSyst.75(2015)
[7]
J.Son,S.B.Kim,Academicpaperrecommendersystemusingmultilevel
simultaneouscitationnetworks,Decis.SupportSyst.105(2018)
[8]
Y.Sebastian,E.-G.Siew,S.O.Orimaye,Learningtheheterogeneousbiblio-
graphicinformationnetworkforliterature-baseddiscovery,Knowl.-Based
Syst.115(2017)
[9]
G.Wang,X.He,C.I.Ishuga,Har-si:Anovelhybridarticlerecommendation
approachintegratingwithsocialinformationinscientificsocialnetwork,
Knowl.-BasedSyst.148(2018)
[10]
A.S.Raamkumar,S.Foo,N.Pang,Usingauthor-specifiedkeywordsin
buildinganinitialreadinglistofresearchpapersinscientificpaper
retrievalandrecommendersystems,Inf.Process.Manage.53(3)(2017)

[11]
W.Zhao,R.Wu,H.Liu,Paperrecommendationbasedontheknowledge
gapbetweenaresearchersbackgroundknowledgeandresearchtarget,
Inf.Process.Manage.52(5)(2016)
[12]
W.Huang,Z.Wu,L.Chen,P.Mitra,C.L.Giles,Aneuralprobabilisticmodel
forcontextbasedcitationrecommendation,in:AAAI,2015,pp.
[13]
X.Liu,Y.Yu,C.Guo,Y.Sun,Meta-path-basedrankingwithpseudo
relevancefeedbackonheterogeneousgraphforcitationrecommendation,
in:Proceedingsofthe23rdACMInternationalConferenceonConference
onInformationandKnowledgeManagement,ACM,2014,pp.
[14]
Q.He,D.Kifer,J.Pei,P.Mitra,C.L.Giles,Citationrecommendationwith-
outauthorsupervision,in:ProceedingsoftheFourthACMInternational
ConferenceonWebSearchandDataMining,ACM,2011,pp.
[15]
Z.Yang,D.Yin,B.D.Davison,Recommendationinacademia:Ajointmulti-
relationalmodel,in:AdvancesinSocialNetworksAnalysisandMining,
ASONAM,2014IEEE/ACMInternationalConferenceon,IEEE,2014,pp.

[16]
X.Tang,X.Wan,X.Zhang,Cross-languagecontext-awarecitationrecom-
mendationinscientificarticles,in:Proceedingsofthe37thInternational
ACMSIGIRConferenceonResearch&DevelopmentinInformation
Retrieval,ACM,2014,pp.
[17]
J.Beel,B.Gipp,S.Langer,C.Breitinger,Paperrecommendersystems:a
literaturesurvey,Int.J.Digit.Libr.17(4)(2016)
[18]
F.Xia,N.Y.Asabere,J.J.Rodrigues,F.Basso,N.Deonauth,W.Wang,Socially-
awarevenuerecommendationforconferenceparticipants,in:Ubiquitous
IntelligenceandComputing,2013IEEE10thInternationalConferenceon
and10thInternationalConferenceonAutonomicandTrustedComputing,
UIC/ATC,IEEE,2013,pp.
/>Page 24
----------------------------------------------------------------------------------------------------<24
T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
[19]
H.Alhoori,R.Furuta,Recommendationofscholarlyvenuesbasedon
dynamicuserinterests,J.Infometrics11(2)(2017)
[20]
E.Medvet,A.Bartoli,G.Piccinin,Publicationvenuerecommendationbased
onpaperabstract,in:ToolswithArtificialIntelligence,ICTAI,2014IEEE
26thInternationalConferenceon,IEEE,2014,pp.
[21]
H.Luong,T.Huynh,S.Gauch,L.Do,K.Hoang,Publicationvenuerecom-
mendationusingauthornetworkspublicationhistory,Intell.Inf.Database
Syst.(2012)
[22]
S.Yu,J.Liu,Z.Yang,Z.Chen,H.Jiang,A.Tolba,F.Xia,PAVE:Personalized
academicvenuerecommendationexploitingco-publicationnetworks,J.
Netw.Comput.Appl.104(2018)
[23]
F.Xia,W.Wang,T.M.Bekele,H.Liu,Bigscholarlydata:Asurvey,IEEE
Trans.BigData3(1)(2017)
[24]
J.Lu,D.Wu,M.Mao,W.Wang,G.Zhang,Recommendersystemapplication
developments:asurvey,Decis.SupportSyst.74(2015)
[25]
N.M.Villegas,C.Snchez,J.Daz-Cely,G.Tamura,Characterizingcontext-
awarerecommendersystems:Asystematicliteraturereview,Knowl.-Based
Syst.140(2018)
[26]
M.C.Pham,D.Kovachev,Y.Cao,G.M.Mbogos,R.Klamma,Enhancing
academiceventparticipationwithcontext-awareandsocialrecommen-
dations,in:AdvancesinSocialNetworksAnalysisandMining,ASONAM,
2012IEEE/ACMInternationalConferenceon,IEEE,2012,pp.
[27]
K.Sugiyama,M.-Y.Kan,Towardshigherrelevanceandserendipityin
scholarlypaperrecommendationbyKazunariSugiyamaandMin-YenKan
withMartinVeselyascoordinator,ACMSIGWEBNewsl.(Winter)(2015)
4.
[28]
Z.Chen,F.Xia,H.Jiang,H.Liu,J.Zhang,AVER:randomwalkbased
academicvenuerecommendation,in:Proceedingsofthe24thInternational
ConferenceonWorldWideWeb,ACM,2015,pp.
[29]
H.Alhoori,Howtoidentifyspecializedresearchcommunitiesrelatedtoa
researcherschanginginterests,in:DigitalLibraries,JCDL,2016IEEE/ACM
JointConferenceon,IEEE,2016,pp.
[30]
D.Wang,Y.Liang,D.Xu,X.Feng,R.Guan,Acontent-basedrecommender
systemforcomputersciencepublications,Knowl.-BasedSyst.157(2018)

[31]
P.Lops,M.DeGemmis,G.Semeraro,Content-basedrecommendersys-
tems:Stateoftheartandtrends,in:RecommenderSystemsHandbook,
Springer,2011,pp.
[32]
R.Klamma,P.M.Cuong,Y.Cao,Youneverwalkalone:Recommend-
ingacademiceventsbasedonsocialnetworkanalysis,in:International
ConferenceonComplexSciences,Springer,2009,pp.
[33]
M.Hornick,P.Tamayo,Extendingrecommendersystemsfordisjoint
user/itemsets:Theconferencerecommendationproblem,IEEETrans.
Knowl.DataEng.24(8)(2012)
[34]
G.Adomavicius,J.Zhang,Stabilityofrecommendationalgorithms,ACM
Trans.Inf.Syst.30(4)(2012)23.
[35]
Z.Yang,B.D.Davison,Distinguishingvenuesbywritingstyles,in:Proceed-
ingsofthe12thACM/IEEE-CSJointConferenceonDigitalLibraries,ACM,
2012,pp.
[36]
Z.Yang,B.D.Davison,Venuerecommendation:Submittingyourpaper
withstyle,in:MachineLearningandApplications,ICMLA,201211th
InternationalConferenceon,Vol.1,IEEE,2012,pp.
[37]
T.Huynh,K.Hoang,Modelingcollaborativeknowledgeofpublishing
activitiesforresearchrecommendation,Comput.Collect.Intell.Technol.
Appl.(2012)
[38]
J.Yu,K.Xie,H.Zhao,F.Liu,Predictionofuserinterestbasedoncollabora-
tivefilteringforpersonalizedacademicrecommendation,in:ComputerSci-
enceandNetworkTechnology,ICCSNT,20122ndInternationalConference
on,IEEE,2012,pp.
[39]
A.J.Trappey,C.V.Trappey,C.-Y.Wu,C.Y.Fan,Y.-L.Lin,Intelligentpatent
recommendationsystemforinnovativedesigncollaboration,J.Netw.
Comput.Appl.36(6)(2013)
[40]
M.Kochen,R.Tagliacozzo,Matchingauthorsandreadersofscientific
papers,Inf.StorageRetr.10(1974)
[41]
M.Errami,J.D.Wren,J.M.Hicks,H.R.Garner,eTBLAST:awebserverto
identifyexpertreviewers,appropriatejournalsandsimilarpublications,
NucleicAcidsRes.35(suppl_2)(2007)
[42]
M.J.Schuemie,J.A.Kors,Jane:suggestingjournals,findingexperts,
Bioinformatics24(5)(2008)
[43]
N.Kang,M.A.Doornenbal,R.J.Schijvenaars,Elsevierjournalfinder:rec-
ommendingjournalsforyourpaper,in:Proceedingsofthe9thACM
ConferenceonRecommenderSystems,ACM,2015,pp.
[44]
W.H.Hsu,A.L.King,M.S.Paradesi,T.Pydimarri,T.Weninger,Collabora-
tiveandstructuralrecommendationoffriendsusingweblog-basedsocial
networkanalysis,in:AAAISpringSymposium:ComputationalApproaches
toAnalyzingWeblogs,vol.6,2006,pp.
[45]
T.Silva,J.Ma,C.Yang,H.Liang,Aprofile-boostedresearchanalytics
frameworktorecommendjournalsformanuscripts,J.Assoc.Inf.Sci.
Technol.66(1)(2015)
[46]
M.C.Pham,Y.Cao,R.Klamma,Clusteringtechniqueforcollaborativefil-
teringandtheapplicationtovenuerecommendation,in:Proc.ofI-KNOW,
Citeseer,2010.
[47]
M.C.Pham,Y.Cao,R.Klamma,M.Jarke,Aclusteringapproachfor
collaborativefilteringrecommendationusingsocialnetworkanalysis.,J.
UCS17(4)(2011)
[48]
H.P.Luong,T.Huynh,S.Gauch,K.Hoang,Exploitingsocialnetworksfor
publicationvenuerecommendations,in:KDIR,2012,pp.
[49]
I.Boukhris,R.Ayachi,Anovelpersonalizedacademicvenuehybridrecom-
mender,in:ComputationalIntelligenceandInformatics,CINTI,2014IEEE
15thInternationalSymposiumon,IEEE,2014,pp.
[50]
E.Minkov,B.Charrow,J.Ledlie,S.Teller,T.Jaakkola,Collaborativefuture
eventrecommendation,in:Proceedingsofthe19thACMInternational
ConferenceonInformationandKnowledgeManagement,ACM,2010,pp.

[51]
Z.Lu,N.Xie,W.Wilbur,Identifyingrelatedjournalsthroughloganalysis,
Bioinformatics25(22)(2009)
[52]
A.Singhal,C.Buckley,M.Mitra,Pivoteddocumentlengthnormalization,
in:Proceedingsofthe19thAnnualInternationalACMSIGIRConference
onResearchandDevelopmentinInformationRetrieval,ACM,1996,pp.

[53]
Y.Sun,B.Norick,J.Han,X.Yan,P.S.Yu,X.Yu,Pathselclus:Integrating
meta-pathselectionwithuser-guidedobjectclusteringinheterogeneous
informationnetworks,ACMTrans.Knowl.Discov.Data7(3)(2013)11.
[54]
Y.Sun,J.Han,Miningheterogeneousinformationnetworks:astructural
analysisapproach,ACMSIGKDDExplor.Newsl.14(2)(2013)
[55]
Y.Sun,J.Han,X.Yan,P.S.Yu,T.Wu,Pathsim:Metapath-basedtop-
ksimilaritysearchinheterogeneousinformationnetworks,Proc.VLDB
Endow.4(11)(2011)
[56]
A.Grover,J.Leskovec,Node2vec:Scalablefeaturelearningfornetworks,
in:Proceedingsofthe22ndACMSIGKDDInternationalConferenceon
KnowledgeDiscoveryandDataMining,ACM,2016,pp.
[57]
B.Zhu,S.Watts,H.Chen,Visualizingsocialnetworkconcepts,Decis.
SupportSyst.49(2)(2010)
[58]
Y.Liang,Q.Li,T.Qian,Findingrelevantpapersbasedoncitationrela-
tions,in:InternationalConferenceonWeb-AgeInformationManagement,
Springer,2011,pp.
[59]
T.Opsahl,F.Agneessens,J.Skvoretz,Nodecentralityinweightednetworks:
Generalizingdegreeandshortestpaths,SocialNetworks32(3)(2010)

[60]
L.C.Freeman,Centralityinsocialnetworksconceptualclarification,Social
Networks1(3)(1978)
[61]
D.M.Blei,A.Y.Ng,M.I.Jordan,Latentdirichletallocation,J.Mach.Learn.
Res.3(Jan)(2003)
[62]
J.H.Lau,T.Baldwin,Anempiricalevaluationofdoc2vecwithpractical
insightsintodocumentembeddinggeneration,2016,arXivpreprint
arXiv:
1607.05368
.
[63]
Q.Le,T.Mikolov,Distributedrepresentationsofsentencesanddocuments,
in:InternationalConferenceonMachineLearning,2014,pp.
[64]
V.D.Blondel,J.-L.Guillaume,R.Lambiotte,E.Lefebvre,Fastunfoldingof
communitiesinlargenetworks,J.Stat.Mech.TheoryExp.2008(10)(2008)
P10008.
[65]
M.E.Newman,M.Girvan,Findingandevaluatingcommunitystructurein
networks,Phys.Rev.E69(2)(2004)026113.
[66]
M.E.Newman,Analysisofweightednetworks,Phys.Rev.E70(5)(2004)
056131.
[67]
R.A.Jarvis,E.A.Patrick,Clusteringusingasimilaritymeasurebasedon
sharednearneighbors,IEEETrans.Comput.100(11)(1973)
[68]
K.Jones,S.Walker,S.E.Robertson,Aprobabilisticmodelofinformation
retrieval:developmentandcomparativeexperiments:Part2,Inf.Process.
Manage.36(6)(2000)
[69]
M.F.Porter,Snowball:ALanguageforStemmingAlgorithms,2001.
[70]
R.Real,J.M.Vargas,Theprobabilisticbasisofjaccardsindexofsimilarity,
Syst.Biol.45(3)(1996)
[71]
I.A.Basheer,M.Hajmeer,Artificialneuralnetworks:fundamentals,
computing,design,andapplication,J.Microbiol.Meth.43(1)(2000)
[72]
H.Tong,C.Faloutsos,J.-Y.Pan,FastRandomWalkwithRestartandits
Applications,IEEE,2006.
[73]
S.Wu,C.Huang,L.Li,F.Crestani,Fusion-basedmethodsforresult
diversificationinwebsearch,Inf.Fusion45(2019)
[74]
S.Wu,Applyingthedatafusiontechniquetoblogopinionretrieval,Expert
Syst.Appl.39(1)(2012)
[75]
D.Lillis,L.Zhang,F.Toolan,R.W.Collier,D.Leonard,J.Dunnion,Estimating
probabilitiesforeffectivedatafusion,in:Proceedingsofthe33rdInterna-
tionalACMSIGIRConferenceonResearchandDevelopmentinInformation
Retrieval,ACM,2010,pp.
[76]
J.A.Aslam,M.Montague,Modelsformetasearch,in:Proceedingsof
the24thAnnualInternationalACMSIGIRConferenceonResearchand
DevelopmentinInformationRetrieval,ACM,2001,pp.
/>Page 25
----------------------------------------------------------------------------------------------------<T.PradhanandS.Pal/Knowledge-BasedSystems189(2020)105092
25
[77]
J.Tang,J.Zhang,L.Yao,J.Li,L.Zhang,Z.Su,Arnetminer:extraction
andminingofacademicsocialnetworks,in:Proceedingsofthe14th
ACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandData
Mining,ACM,2008,pp.
[78]
M.Deshpande,G.Karypis,Item-basedtop-nrecommendationalgorithms,
ACMTrans.Inf.Syst.22(1)(2004)
[79]
H.Stuckenschmidt,Approximateinformationfilteringonthesemantic
web,in:AnnualConferenceonArtificialIntelligence,Springer,2002,pp.

[80]
M.Sokolova,G.Lapalme,Asystematicanalysisofperformancemeasures
forclassificationtasks,Inf.Process.Manage.45(4)(2009)
[81]
E.Gibaja,S.Ventura,Atutorialonmultilabellearning,ACMComput.
Surv.47(3)(2015)
http://dx.doi.org/10.1145/2716262
,URL
http://doi.acm.org/10.1145/2716262
.
[82]
M.Kunaver,T.Porl,Diversityinrecommendersurvey,
Knowl.-BasedSyst.123(2017)
[83]
G.Adomavicius,J.Zhang,Improvingstabilityofrecommendersystems:a
meta-algorithmicapproach,IEEETrans.Knowl.DataEng.27(6)(2014)

[84]
C.Desrosiers,G.Karypis,Acomprehensivesurveyofneighborhood-based
recommendationmethods,in:RecommenderSystemsHandbook,Springer,
2011,pp.
/>